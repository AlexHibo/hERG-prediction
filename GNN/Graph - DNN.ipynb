{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bf300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score,accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846b086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from PyBioMed.PyMolecule.cats2d import CATS2D\n",
    "from PyBioMed.PyMolecule import cats2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0856d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_graph(smiles_list):\n",
    "    adj = []\n",
    "    adj_norm = []\n",
    "    features = []\n",
    "    maxNumAtoms = 100\n",
    "    cnt = 0\n",
    "    new_smiles_list = []\n",
    "    for i in smiles_list:\n",
    "        cnt+=1\n",
    "        # Mol\n",
    "        iMol = Chem.MolFromSmiles(i.strip())\n",
    "        #Adj\n",
    "        iAdjTmp = Chem.rdmolops.GetAdjacencyMatrix(iMol)\n",
    "        # Feature\n",
    "        if( iAdjTmp.shape[0] <= maxNumAtoms):\n",
    "            # Feature-preprocessing\n",
    "            iFeature = np.zeros((maxNumAtoms, 65))\n",
    "            iFeatureTmp = []\n",
    "            for atom in iMol.GetAtoms():\n",
    "                iFeatureTmp.append( atom_feature(atom) ) ### atom features only\n",
    "            iFeature[0:len(iFeatureTmp), 0:65] = iFeatureTmp ### 0 padding for feature-set\n",
    "            features.append(iFeature)\n",
    "\n",
    "            # Adj-preprocessing\n",
    "            iAdj = np.zeros((maxNumAtoms, maxNumAtoms))\n",
    "            iAdj[0:len(iFeatureTmp), 0:len(iFeatureTmp)] = iAdjTmp + np.eye(len(iFeatureTmp))\n",
    "            adj.append(np.asarray(iAdj))\n",
    "            new_smiles_list.append(i)\n",
    "        else :\n",
    "            print(\"Molecule is too big\")\n",
    "            adj_norm.append()\n",
    "            \n",
    "    features = np.asarray(features)\n",
    "    adj = np.asarray(adj)\n",
    "    # ensure the the length is the same as the input\n",
    "    assert len(features) == len(smiles_list)\n",
    "    return features, adj, new_smiles_list\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def atom_feature(atom):\n",
    "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
    "                                      ['C', 'N', 'O', 'S', 'F', 'H', 'Si', 'P', 'Cl', 'Br',\n",
    "                                       'Li', 'Na', 'K', 'Mg', 'Ca', 'Fe', 'As', 'Al', 'I', 'B',\n",
    "                                       'V', 'Tl', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn',\n",
    "                                       'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'Mn', 'Cr', 'Pt', 'Hg', 'Pb']) +\n",
    "                    one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    one_of_k_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]) +\n",
    "                    one_of_k_encoding(atom.GetTotalValence(), [0, 1, 2, 3, 4, 5, 6]) + [atom.GetIsAromatic()] + get_ring_info(atom))\n",
    "\n",
    "def get_ring_info(atom):\n",
    "    ring_info_feature = []\n",
    "    for i in range(3, 9):\n",
    "        if atom.IsInRingSize(i):\n",
    "            ring_info_feature.append(1)\n",
    "        else:\n",
    "            ring_info_feature.append(0)\n",
    "    return ring_info_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d8ff4",
   "metadata": {},
   "source": [
    "MODEL de GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8cc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_gcn_layers, \n",
    "                 dnn_hidden_nodes, num_dnn_layers, dropout_rate, l2_lambda, num_classes=1):\n",
    "        \"\"\"\n",
    "        Enhanced Graph Neural Network with adaptive batch normalization\n",
    "        \"\"\"\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        \n",
    "        # Regularization parameters\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.l2_lambda = l2_lambda\n",
    "        \n",
    "        # Graph Convolution Layers\n",
    "        self.gcn_layers = nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.gcn_layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(num_features, hidden_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_channels, momentum=0.1),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Add GCN layers\n",
    "        for _ in range(num_gcn_layers - 1):\n",
    "            self.gcn_layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_channels, hidden_channels),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(hidden_channels, momentum=0.1),\n",
    "                    nn.Dropout(dropout_rate)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Hidden Layers\n",
    "        self.dnn_layers = nn.ModuleList()\n",
    "        input_size = hidden_channels\n",
    "        \n",
    "        for _ in range(num_dnn_layers):\n",
    "            self.dnn_layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(input_size, dnn_hidden_nodes),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(dnn_hidden_nodes, momentum=0.1),\n",
    "                    nn.Dropout(dropout_rate)\n",
    "                )\n",
    "            )\n",
    "            input_size = dnn_hidden_nodes\n",
    "        \n",
    "        # Final output layer\n",
    "        self.output_layer = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def graph_convolution(self, X, A):\n",
    "        \"\"\"\n",
    "        Enhanced graph convolution with adjacency normalization\n",
    "        \"\"\"\n",
    "        # Normalize adjacency matrix\n",
    "        degrees = torch.sum(A, dim=2)\n",
    "        D_inv_sqrt = torch.pow(degrees + 1e-7, -0.5)\n",
    "        A_norm = A * D_inv_sqrt.unsqueeze(-1) * D_inv_sqrt.unsqueeze(-2)\n",
    "        \n",
    "        for layer in self.gcn_layers:\n",
    "            # Linear transformation\n",
    "            X = layer[0](X)\n",
    "            \n",
    "            # Message passing\n",
    "            X = torch.bmm(A_norm, X)\n",
    "            \n",
    "            # Activation\n",
    "            X = layer[1](X)\n",
    "            \n",
    "            # Batch normalization \n",
    "            X = layer[2](X.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "            # Dropout\n",
    "            X = layer[3](X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def forward(self, X, A):\n",
    "        \"\"\"\n",
    "        Forward pass with graph convolution and regularization\n",
    "        \"\"\"\n",
    "        # Graph convolution\n",
    "        X = self.graph_convolution(X, A)\n",
    "        \n",
    "        # Global pooling\n",
    "        X = torch.mean(X, dim=1)\n",
    "        \n",
    "        # Dense layers\n",
    "        for layer in self.dnn_layers:\n",
    "            X = layer[0](X)  # Linear\n",
    "            X = layer[1](X)  # ReLU\n",
    "            X = layer[2](X)  # BatchNorm\n",
    "            X = layer[3](X)  # Dropout\n",
    "        \n",
    "        # Output layer\n",
    "        return self.output_layer(X)\n",
    "\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, X_data, A_data, y_data):\n",
    "        \"\"\"\n",
    "        Dataset with tensor conversion\n",
    "        \"\"\"\n",
    "        self.X = torch.tensor(X_data, dtype=torch.float32)\n",
    "        self.A = torch.tensor(A_data, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_data, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.A[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def train_graph_neural_network(\n",
    "    model, train_loader,test_loader, val_loader=None, \n",
    "    epochs=100, \n",
    "    learning_rate=0.001, \n",
    "    weight_decay=1e-5, \n",
    "    patience=10, \n",
    "    save_path=\"gnn_model.pth\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Training function with early stopping and validation\n",
    "    \"\"\"\n",
    "    # Optimizer with weight decay\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "        \n",
    "    plt.ion()\n",
    "    fig, ax = plt.subplots()\n",
    "    epoches = []\n",
    "    kappa_scores = []\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds = []\n",
    "        train_true = []\n",
    "        \n",
    "        for X_batch, A_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch, A_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_preds.extend(torch.sigmoid(outputs).detach().numpy())\n",
    "            train_true.extend(y_batch.numpy())\n",
    "        \n",
    "        # Validation phase\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            val_preds = []\n",
    "            val_true = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for X_batch, A_batch, y_batch in val_loader:\n",
    "                    outputs = model(X_batch, A_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    val_losses.append(loss.item())\n",
    "                    \n",
    "                    val_preds.extend(torch.sigmoid(outputs).numpy())\n",
    "                    val_true.extend(y_batch.numpy())\n",
    "            \n",
    "            # Compute metrics\n",
    "            val_loss = np.mean(val_losses)\n",
    "            val_preds_binary = (np.array(val_preds) > 0.5).astype(int)\n",
    "            \n",
    "            # Logging and early stopping\n",
    "            print(f\"Epoch {epoch+1}: Val Loss {val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            \n",
    "        # Évaluation après l'époque (par exemple sur val_loader)\n",
    "        d = evaluate_graph_neural_network(model, test_loader)\n",
    "        kappa = d['Cohens_kappa']\n",
    "\n",
    "        # Stockage\n",
    "        epoches.append(epoch)\n",
    "        kappa_scores.append(kappa)\n",
    "        # print(epoches)\n",
    "        # print(kappa_scores)\n",
    "\n",
    "        # # Mise à jour du graphique\n",
    "        # plt.plot(epoches, kappa_scores, label='Cohen\\'s Kappa')\n",
    "        # plt.xlabel('Epochs')\n",
    "        # plt.ylabel('Cohen\\'s Kappa')\n",
    "        # plt.show()\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_graph_neural_network(model, dataloader):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, A_batch, y_batch in dataloader:\n",
    "            outputs = model(X_batch, A_batch)\n",
    "            preds = torch.sigmoid(outputs).numpy().squeeze()\n",
    "            preds_binary = (preds > 0.5).astype(int)\n",
    "            \n",
    "            all_preds.extend(preds_binary)\n",
    "            all_true.extend(y_batch.numpy())\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_true, all_preds)\n",
    "    precision = precision_score(all_true, all_preds)\n",
    "    recall = recall_score(all_true, all_preds)\n",
    "    f1 = f1_score(all_true, all_preds)\n",
    "    kappa = cohen_kappa_score(all_true, all_preds)\n",
    "    \n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Precision: {precision:.4f}\")\n",
    "    # print(f\"Recall: {recall:.4f}\")\n",
    "    # print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "    # Return metrics as a dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'Cohens_kappa': kappa\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1eb09c",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c342b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train/train_80.csv\")\n",
    "data_test = pd.read_csv(\"train/valid_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf50a1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# train model and save weights\u001b[39;00m\n\u001b[32m     31\u001b[39m model = GraphNeuralNetwork(**gnn_params)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m model = \u001b[43mtrain_graph_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgnn_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# # Evaluate the model\u001b[39;00m\n\u001b[32m     36\u001b[39m evaluate_graph_neural_network(model, test_loader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 131\u001b[39m, in \u001b[36mtrain_graph_neural_network\u001b[39m\u001b[34m(model, train_loader, test_loader, val_loader, epochs, learning_rate, weight_decay, patience, save_path)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03mTraining function with early stopping and validation\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Optimizer with weight decay\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m optimizer = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;66;03m# Learning rate scheduler\u001b[39;00m\n\u001b[32m    138\u001b[39m scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n\u001b[32m    139\u001b[39m     optimizer, mode=\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m5\u001b[39m\n\u001b[32m    140\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adamw.py:37\u001b[39m, in \u001b[36mAdamW.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     24\u001b[39m     params: ParamsT,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     fused: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     36\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adam.py:100\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     88\u001b[39m     lr=lr,\n\u001b[32m     89\u001b[39m     betas=betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m     99\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:369\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    366\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_compile.py:46\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_dynamo/__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:57\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     58\u001b[39m     config,\n\u001b[32m     59\u001b[39m     exc,\n\u001b[32m     60\u001b[39m     graph_break_hints,\n\u001b[32m     61\u001b[39m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[32m     62\u001b[39m     trace_rules,\n\u001b[32m     63\u001b[39m     variables,\n\u001b[32m     64\u001b[39m )\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     get_indexof,\n\u001b[32m     67\u001b[39m     JUMP_OPNAMES,\n\u001b[32m     68\u001b[39m     livevars_analysis,\n\u001b[32m     69\u001b[39m     propagate_line_nums,\n\u001b[32m     70\u001b[39m )\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     72\u001b[39m     cleaned_instructions,\n\u001b[32m     73\u001b[39m     create_call_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     unique_id,\n\u001b[32m     81\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     BuiltinVariable,\n\u001b[32m     34\u001b[39m     FunctionalCallVariable,\n\u001b[32m     35\u001b[39m     FunctorchHigherOrderVariable,\n\u001b[32m     36\u001b[39m     LocalGeneratorFunctionVariable,\n\u001b[32m     37\u001b[39m     LocalGeneratorObjectVariable,\n\u001b[32m     38\u001b[39m     NestedUserFunctionVariable,\n\u001b[32m     39\u001b[39m     PolyfilledFunctionVariable,\n\u001b[32m     40\u001b[39m     SkipFunctionVariable,\n\u001b[32m     41\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m     42\u001b[39m     UserFunctionVariable,\n\u001b[32m     43\u001b[39m     UserMethodVariable,\n\u001b[32m     44\u001b[39m )\n\u001b[32m     47\u001b[39m np: Optional[types.ModuleType] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package implements variable tracking and symbolic execution capabilities for Dynamo,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mwhich are essential for converting Python code into FX graphs. It provides a comprehensive\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03mallows Dynamo to accurately trace and optimize Python code while preserving its semantics.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuiltin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_dynamo/variables/base.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcurrent_scope_id\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m current_scope_id\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unimplemented, unimplemented_v2\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttrSource, Source\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cmp_name_to_op_mapping, istype\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_dynamo/guards.py:91\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mweak\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorWeakRef\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, exc, mutation_guard\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval_frame\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m set_guard_error_hook\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     93\u001b[39m     AttrProxySource,\n\u001b[32m     94\u001b[39m     AttrSource,\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     WeakRefCallSource,\n\u001b[32m    125\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    127\u001b[39m     CacheEntry,\n\u001b[32m    128\u001b[39m     DynamoFrameType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    132\u001b[39m     GuardFn,\n\u001b[32m    133\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:936\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1032\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1131\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "smiles_list = data_train['smiles'].tolist() \n",
    "smiles_list_test = data_test['smiles'].tolist()\n",
    "y_train = data_train['class'].values\n",
    "y_test = data_test['class'].values\n",
    "\n",
    "# Convert to graph data\n",
    "\n",
    "X_train, A_train, smiles_list = convert_to_graph(smiles_list)\n",
    "X_test, A_test, smiles_list_test = convert_to_graph(smiles_list_test)\n",
    "\n",
    "    # Model hyperparameters\n",
    "num_features = X_train.shape[2]\n",
    "gnn_params = {\n",
    "        'num_features': num_features,\n",
    "        'hidden_channels': 128,\n",
    "        'num_gcn_layers': 4,\n",
    "        'dnn_hidden_nodes': 512,\n",
    "        'num_dnn_layers': 2,\n",
    "        'dropout_rate': 0.33356257977269954,\n",
    "        'l2_lambda': 0.0007517360053320633\n",
    "    }\n",
    "\n",
    "    # Prepare datasets\n",
    "train_dataset = GraphDataset(X_train, A_train, y_train)\n",
    "test_dataset = GraphDataset(X_test, A_test, y_test)\n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "    # train model and save weights\n",
    "model = GraphNeuralNetwork(**gnn_params)\n",
    "model = train_graph_neural_network(model, train_loader,test_loader, val_loader=None, epochs=200, learning_rate=0.0001, weight_decay=1e-5, patience=2, save_path=\"gnn_model.pth\")\n",
    "\n",
    "\n",
    "    # # Evaluate the model\n",
    "evaluate_graph_neural_network(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ea72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"gnn_model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1882e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               smiles  predictions\n",
      "0   O=C(O)C(Cc1ccccc1)N1CCC(CN2CCC(Oc3ccc(CO)c(Cl)...     0.005069\n",
      "1   CN1CCN(CCCn2nc(C3=C(c4cn(-c5ccc6ccccc6c5)c5ccc...     0.978255\n",
      "2   OCC1(N2CCN(C3CCc4ccc(OCc5noc(-c6ccc(Cl)cc6)n5)...     0.978666\n",
      "3   CCn1c(=O)oc2ccc(-c3ccc(CC(C#N)NC(=O)C4CNCCCO4)...     0.004499\n",
      "4   O=C(C1CC1c1ccc(C(F)(F)F)cc1)N1CCN(S(=O)(=O)c2c...     0.998825\n",
      "5   O=C(O)CCCCOc1ccc2ncc(F)c(CCC34CCC(NCc5ccc6c(n5...     0.287143\n",
      "6   COc1nc(N2CC3C(=O)N(C)C(=N)NC3(c3ccc(F)cc3F)C2)...     0.645876\n",
      "7     CNC(=O)c1ccc(-c2ccc3c(c2)CCN(CCN2CCCC2)C3=O)cc1     0.341835\n",
      "8     Nc1nc(-c2ccc(F)cc2)cn1CC(O)c1ccc(C(F)(F)F)cc1Cl     0.581977\n",
      "9         CCCNC(=O)C1c2ccccc2C(=O)N1CC(C)c1ccc(Cl)cc1     0.215037\n",
      "10         Cn1cc(C2CC3CSC(N)=NC3(c3ccc(F)cc3F)CO2)cn1     0.370659\n",
      "11    CCCCCN(CCC12CC3CC(CC(C3)C1)C2)C(=O)NCCCc1ccncc1     0.908153\n",
      "12  O=[N+]([O-])c1ccc(CCN2CCN(CCc3ccc([N+](=O)[O-]...     0.999863\n",
      "13  Cn1c(SCCCN2CCC3(CC3c3ccc(C(F)(F)F)cc3)C2)nnc1-...     0.999799\n",
      "14  CCn1cc(C2(c3cccc(-c4cncnc4)c3)N=C(N)c3c(F)cccc...     0.976281\n",
      "15                           CCCCCCCCCC[N+](CC)(CC)CC     0.748921\n",
      "16  CSc1sc(C(=N)N)cc1S(=O)(=O)c1cccc(-c2cc(C)ccc2N...     0.946353\n",
      "17           NC(=O)c1cccc(OC2CC3CCC(C2)N3Cc2ccccn2)c1     0.998992\n",
      "18  CC(C)Cc1cc(C(F)(F)F)cc(COCC2(c3ccc(F)cc3)CCN(C...     0.149485\n",
      "19  FC(F)(F)c1cccc(Cn2ccc3c(OC4CCN(Cc5cscn5)CC4)nc...     0.984225\n",
      "20  COc1cc(OC)cc(C(=O)NCC2(C#N)CCN(Cc3ccccc3C(F)(F...     0.978135\n",
      "21  CCN(CC)c1cc(C(F)(F)F)cc(COCC2(c3ccc(F)cc3)CCN(...     0.566647\n",
      "22            N#CC(=C(N)Sc1ccc(N)cc1)c1ccccc1C(F)(F)F     0.622709\n",
      "23    CC1(C)C2CCC13CCN(CCN1CCN(c4cccc(Cl)c4)C1=O)C3C2     0.944908\n",
      "24  NCCCCOc1ccc2ncc(F)c(CCC34CCC(NCc5ccc6c(n5)NC(=...     0.902769\n",
      "25            c1cncc(C(Cc2ccccc2-c2ccncc2)c2cccnc2)c1     0.010768\n",
      "26  COc1cccc(-c2cc3c(NC4CCC(C)(N)C4(C)C)c(C(N)=O)c...     0.872599\n",
      "27     CN(C)CCN(C)C1CCN(c2nc3ccccc3n2Cc2ccc(F)cc2)CC1     0.993745\n",
      "28   N#Cc1ccc(-c2ccc(CC(C#N)NC(=O)C3(N)CCCCC3)cc2)cc1     0.193564\n",
      "29  CCc1nc2cc(CN3CCC(NC(=O)c4cc(=O)c5ccc(F)cc5o4)C...     0.977560\n"
     ]
    }
   ],
   "source": [
    "model = GraphNeuralNetwork(**gnn_params)  # instancier ton modèle avec ses paramètres\n",
    "model.load_state_dict(torch.load(\"gnn_model_final.pth\"))  # charger les poids sauvegardés\n",
    "model.eval()\n",
    "\n",
    "data1 = pd.read_csv(\"train/valid_20.csv\")\n",
    "new_smiles_list = data1[\"smiles\"].tolist()\n",
    "\n",
    "colonne1=data1['smiles']\n",
    "\n",
    "\n",
    "X_new, A_new, _ = convert_to_graph(new_smiles_list)\n",
    "\n",
    "new_dataset = GraphDataset(X_new, A_new, np.zeros(len(X_new)))  # y factice\n",
    "new_loader = DataLoader(new_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 3. Prédire\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, A_batch, _ in new_loader:\n",
    "        outputs = model(X_batch, A_batch)\n",
    "        preds = torch.sigmoid(outputs).squeeze().numpy()\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "serie = pd.Series(all_preds, name='predictions')\n",
    "merged_df = pd.concat([colonne1, serie], axis=1)\n",
    "print(merged_df.head(30))\n",
    "\n",
    "# 4. Sauvegarder les résultats\n",
    "merged_df.to_csv(\"predictions_GNN.csv\", index=False)\n",
    "\n",
    "new_data = pd.read_csv(\"data/test_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "646857d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier predictions_GNN.csv généré avec succès.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Charger le modèle entraîné\n",
    "model = GraphNeuralNetwork(**gnn_params)  # Remplace par tes vrais paramètres\n",
    "model.load_state_dict(torch.load(\"gnn_model_final.pth\"))  # Charger les poids\n",
    "model.eval()\n",
    "\n",
    "# 2. Charger les nouveaux SMILES à prédire\n",
    "new_data = pd.read_csv(\"/Users/rayanedakhlaoui/Desktop/VivaAfricAI/Final/test/test_1.csv\")\n",
    "new_smiles_list = new_data[\"smiles\"].tolist()  # Assure-toi que la colonne s'appelle \"smiles\"\n",
    "\n",
    "# 3. Transformer les SMILES en graphes\n",
    "X_new, A_new, _ = convert_to_graph(new_smiles_list)\n",
    "new_dataset = GraphDataset(X_new, A_new, np.zeros(len(X_new)))  # Labels factices\n",
    "new_loader = DataLoader(new_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 4. Prédire\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, A_batch, _ in new_loader:\n",
    "        outputs = model(X_batch, A_batch)\n",
    "        preds = torch.sigmoid(outputs).squeeze().numpy()\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "# 5. Fusionner et sauvegarder\n",
    "serie = pd.Series(all_preds, name='predictions')\n",
    "merged_df = pd.concat([new_data[\"smiles\"], serie], axis=1)\n",
    "merged_df.to_csv(\"predictions_GNN.csv\", index=False)\n",
    "\n",
    "print(\"Fichier predictions_GNN.csv généré avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920c0ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 4296)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a27e3653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"predictions_GNN.csv\").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
