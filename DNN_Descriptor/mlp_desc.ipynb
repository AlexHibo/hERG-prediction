{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2d9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13d5a3",
   "metadata": {},
   "source": [
    "### MLP class for Descriptor features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62bb95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptorMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_nodes, hidden_layers, dropout_rate):\n",
    "        super(DescriptorMLP, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_nodes)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "        self.fc_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_nodes, hidden_nodes) for _ in range(hidden_layers - 1)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(hidden_nodes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.fc_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = torch.sigmoid(self.fc_out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23e1d9",
   "metadata": {},
   "source": [
    "### Class DescriptorDataset for convertion in torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a4a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptorDataset(Dataset):\n",
    "    def __init__(self, X_data: np.ndarray, y_data: np.ndarray):\n",
    "        self.X = torch.tensor(X_data, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_data, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86080b8",
   "metadata": {},
   "source": [
    "### Prediction fct°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54d06030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mlp(model: nn.Module, X_test: np.ndarray) -> np.ndarray:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_pred = model(X_test_tensor).squeeze()\n",
    "        return y_pred.round().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8302ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dnn_with_dataloader(X_train, y_train, model, batch_size=32, learning_rate=0.001, epochs=100, save_path=\"descriptor_based_dnn.pth\"):\n",
    "    # loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataset = DescriptorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop with tqdm progress bar\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        epoch_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
    "        \n",
    "        for inputs, labels in epoch_bar:\n",
    "            # Forward pass\n",
    "            y_pred = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(y_pred, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "            train_acc = np.mean(predict_mlp(model, X_train) == y_train)\n",
    "            print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model trained and saved at {save_path}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "064d33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_descriptor_based_DNN(smiles_list,C_total, trained_model):\n",
    "    # Convert data to PyTorch tensors\n",
    "    C_total_tensor = torch.tensor(C_total, dtype=torch.float32)\n",
    "\n",
    "    # Model initialization\n",
    "    input_size = C_total.shape[1]  # number of features\n",
    "    hidden_nodes = 892\n",
    "    hidden_layers = 4\n",
    "    dropout_rate = 0.2\n",
    "    \n",
    "    model = DescriptorMLP(input_size, hidden_nodes, hidden_layers, dropout_rate)\n",
    "    \n",
    "    # Load the trained model (assuming it is saved in .pt format)\n",
    "    model.load_state_dict(torch.load(trained_model))\n",
    "    model.eval()\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Make predictions\n",
    "        y_pred = model(C_total_tensor).squeeze()\n",
    "\n",
    "        for i, smi in enumerate(smiles_list):\n",
    "            prob = y_pred[i].item()  # Convert tensor to native Python float\n",
    "            results[smi] = prob\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5436748d",
   "metadata": {},
   "source": [
    "### Descriptors to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca588571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_selected_features(data):\n",
    "    # Liste des descripteurs à extraire\n",
    "    descriptors_to_extract = [\n",
    "        'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v',\n",
    "        'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'EState_VSA1', 'EState_VSA10',\n",
    "        'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6',\n",
    "        'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'ExactMolWt', 'FpDensityMorgan1', 'FpDensityMorgan2',\n",
    "        'FpDensityMorgan3', 'FractionCSP3', 'HallKierAlpha', 'HeavyAtomCount', 'HeavyAtomMolWt', 'Kappa1',\n",
    "        'Kappa2', 'Kappa3', 'LabuteASA', 'MaxAbsEStateIndex', 'MaxAbsPartialCharge', 'MaxEStateIndex',\n",
    "        'MaxPartialCharge', 'MinAbsEStateIndex', 'MinAbsPartialCharge', 'MinEStateIndex', 'MinPartialCharge',\n",
    "        'MolLogP', 'MolMR', 'MolWt', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles',\n",
    "        'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings',\n",
    "        'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRadicalElectrons', 'NumRotatableBonds',\n",
    "        'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumValenceElectrons',\n",
    "        'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2',\n",
    "        'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9',\n",
    "        'RingCount', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6',\n",
    "        'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12',\n",
    "        'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8',\n",
    "        'SlogP_VSA9', 'TPSA', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4',\n",
    "        'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'fr_Al_COO', 'fr_Al_OH',\n",
    "        'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2',\n",
    "        'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O',\n",
    "        'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate',\n",
    "        'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide',\n",
    "        'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine',\n",
    "        'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone',\n",
    "        'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam',\n",
    "        'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho',\n",
    "        'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond',\n",
    "        'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine',\n",
    "        'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole',\n",
    "        'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea', 'qed'\n",
    "    ]\n",
    "    C_total = data[descriptors_to_extract]\n",
    "    smiles_list = data['smiles']\n",
    "    return C_total, smiles_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cdc6cd",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d883ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 59/59 [00:00<00:00, 68.75it/s]\n",
      "Epoch 2/100: 100%|██████████| 59/59 [00:00<00:00, 82.69it/s]\n",
      "Epoch 3/100: 100%|██████████| 59/59 [00:00<00:00, 84.33it/s]\n",
      "Epoch 4/100: 100%|██████████| 59/59 [00:00<00:00, 81.03it/s]\n",
      "Epoch 5/100: 100%|██████████| 59/59 [00:00<00:00, 80.52it/s]\n",
      "Epoch 6/100: 100%|██████████| 59/59 [00:00<00:00, 80.34it/s]\n",
      "Epoch 7/100: 100%|██████████| 59/59 [00:00<00:00, 81.20it/s]\n",
      "Epoch 8/100: 100%|██████████| 59/59 [00:00<00:00, 80.85it/s]\n",
      "Epoch 9/100: 100%|██████████| 59/59 [00:00<00:00, 79.29it/s]\n",
      "Epoch 10/100: 100%|██████████| 59/59 [00:00<00:00, 79.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3727\n",
      "Train Accuracy: 0.8816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 59/59 [00:00<00:00, 68.64it/s]\n",
      "Epoch 12/100: 100%|██████████| 59/59 [00:00<00:00, 86.98it/s]\n",
      "Epoch 13/100: 100%|██████████| 59/59 [00:00<00:00, 87.33it/s]\n",
      "Epoch 14/100: 100%|██████████| 59/59 [00:00<00:00, 88.76it/s]\n",
      "Epoch 15/100: 100%|██████████| 59/59 [00:00<00:00, 88.82it/s]\n",
      "Epoch 16/100: 100%|██████████| 59/59 [00:00<00:00, 90.25it/s]\n",
      "Epoch 17/100: 100%|██████████| 59/59 [00:00<00:00, 88.38it/s]\n",
      "Epoch 18/100: 100%|██████████| 59/59 [00:00<00:00, 89.57it/s]\n",
      "Epoch 19/100: 100%|██████████| 59/59 [00:00<00:00, 89.62it/s]\n",
      "Epoch 20/100: 100%|██████████| 59/59 [00:00<00:00, 89.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.2427\n",
      "Train Accuracy: 0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 59/59 [00:00<00:00, 81.62it/s]\n",
      "Epoch 22/100: 100%|██████████| 59/59 [00:00<00:00, 85.74it/s]\n",
      "Epoch 23/100: 100%|██████████| 59/59 [00:00<00:00, 85.29it/s]\n",
      "Epoch 24/100: 100%|██████████| 59/59 [00:00<00:00, 89.14it/s]\n",
      "Epoch 25/100: 100%|██████████| 59/59 [00:00<00:00, 84.83it/s]\n",
      "Epoch 26/100: 100%|██████████| 59/59 [00:00<00:00, 80.06it/s]\n",
      "Epoch 27/100: 100%|██████████| 59/59 [00:00<00:00, 85.16it/s]\n",
      "Epoch 28/100: 100%|██████████| 59/59 [00:00<00:00, 88.69it/s]\n",
      "Epoch 29/100: 100%|██████████| 59/59 [00:00<00:00, 89.86it/s]\n",
      "Epoch 30/100: 100%|██████████| 59/59 [00:00<00:00, 88.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.1463\n",
      "Train Accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 59/59 [00:00<00:00, 88.83it/s]\n",
      "Epoch 32/100: 100%|██████████| 59/59 [00:00<00:00, 89.31it/s]\n",
      "Epoch 33/100: 100%|██████████| 59/59 [00:00<00:00, 88.77it/s]\n",
      "Epoch 34/100: 100%|██████████| 59/59 [00:00<00:00, 85.31it/s]\n",
      "Epoch 35/100: 100%|██████████| 59/59 [00:00<00:00, 83.75it/s]\n",
      "Epoch 36/100: 100%|██████████| 59/59 [00:00<00:00, 88.58it/s]\n",
      "Epoch 37/100: 100%|██████████| 59/59 [00:00<00:00, 90.69it/s]\n",
      "Epoch 38/100: 100%|██████████| 59/59 [00:00<00:00, 88.42it/s]\n",
      "Epoch 39/100: 100%|██████████| 59/59 [00:00<00:00, 89.96it/s]\n",
      "Epoch 40/100: 100%|██████████| 59/59 [00:00<00:00, 86.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.1005\n",
      "Train Accuracy: 0.9931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 59/59 [00:00<00:00, 88.27it/s]\n",
      "Epoch 42/100: 100%|██████████| 59/59 [00:00<00:00, 82.14it/s]\n",
      "Epoch 43/100: 100%|██████████| 59/59 [00:00<00:00, 90.01it/s]\n",
      "Epoch 44/100: 100%|██████████| 59/59 [00:00<00:00, 89.91it/s]\n",
      "Epoch 45/100: 100%|██████████| 59/59 [00:00<00:00, 86.78it/s]\n",
      "Epoch 46/100: 100%|██████████| 59/59 [00:00<00:00, 84.06it/s]\n",
      "Epoch 47/100: 100%|██████████| 59/59 [00:00<00:00, 91.52it/s]\n",
      "Epoch 48/100: 100%|██████████| 59/59 [00:00<00:00, 90.48it/s]\n",
      "Epoch 49/100: 100%|██████████| 59/59 [00:00<00:00, 88.56it/s]\n",
      "Epoch 50/100: 100%|██████████| 59/59 [00:00<00:00, 83.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.0700\n",
      "Train Accuracy: 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 59/59 [00:00<00:00, 85.32it/s]\n",
      "Epoch 52/100: 100%|██████████| 59/59 [00:00<00:00, 90.47it/s]\n",
      "Epoch 53/100: 100%|██████████| 59/59 [00:00<00:00, 91.87it/s]\n",
      "Epoch 54/100: 100%|██████████| 59/59 [00:00<00:00, 84.53it/s]\n",
      "Epoch 55/100: 100%|██████████| 59/59 [00:00<00:00, 84.27it/s]\n",
      "Epoch 56/100: 100%|██████████| 59/59 [00:00<00:00, 81.43it/s]\n",
      "Epoch 57/100: 100%|██████████| 59/59 [00:00<00:00, 86.72it/s]\n",
      "Epoch 58/100: 100%|██████████| 59/59 [00:00<00:00, 85.47it/s]\n",
      "Epoch 59/100: 100%|██████████| 59/59 [00:00<00:00, 84.04it/s]\n",
      "Epoch 60/100: 100%|██████████| 59/59 [00:00<00:00, 85.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.0443\n",
      "Train Accuracy: 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 59/59 [00:00<00:00, 84.13it/s]\n",
      "Epoch 62/100: 100%|██████████| 59/59 [00:00<00:00, 85.77it/s]\n",
      "Epoch 63/100: 100%|██████████| 59/59 [00:00<00:00, 78.27it/s]\n",
      "Epoch 64/100: 100%|██████████| 59/59 [00:00<00:00, 83.77it/s]\n",
      "Epoch 65/100: 100%|██████████| 59/59 [00:00<00:00, 88.42it/s]\n",
      "Epoch 66/100: 100%|██████████| 59/59 [00:00<00:00, 88.40it/s]\n",
      "Epoch 67/100: 100%|██████████| 59/59 [00:00<00:00, 88.31it/s]\n",
      "Epoch 68/100: 100%|██████████| 59/59 [00:00<00:00, 87.76it/s]\n",
      "Epoch 69/100: 100%|██████████| 59/59 [00:00<00:00, 88.29it/s]\n",
      "Epoch 70/100: 100%|██████████| 59/59 [00:00<00:00, 88.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0436\n",
      "Train Accuracy: 0.9963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 59/59 [00:00<00:00, 80.53it/s]\n",
      "Epoch 72/100: 100%|██████████| 59/59 [00:00<00:00, 87.95it/s]\n",
      "Epoch 73/100: 100%|██████████| 59/59 [00:00<00:00, 86.42it/s]\n",
      "Epoch 74/100: 100%|██████████| 59/59 [00:00<00:00, 87.33it/s]\n",
      "Epoch 75/100: 100%|██████████| 59/59 [00:00<00:00, 87.39it/s]\n",
      "Epoch 76/100: 100%|██████████| 59/59 [00:00<00:00, 83.95it/s]\n",
      "Epoch 77/100: 100%|██████████| 59/59 [00:00<00:00, 86.69it/s]\n",
      "Epoch 78/100: 100%|██████████| 59/59 [00:00<00:00, 88.39it/s]\n",
      "Epoch 79/100: 100%|██████████| 59/59 [00:00<00:00, 88.26it/s]\n",
      "Epoch 80/100: 100%|██████████| 59/59 [00:00<00:00, 89.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0315\n",
      "Train Accuracy: 0.9984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 59/59 [00:00<00:00, 86.04it/s]\n",
      "Epoch 82/100: 100%|██████████| 59/59 [00:00<00:00, 86.39it/s]\n",
      "Epoch 83/100: 100%|██████████| 59/59 [00:00<00:00, 86.10it/s]\n",
      "Epoch 84/100: 100%|██████████| 59/59 [00:00<00:00, 84.39it/s]\n",
      "Epoch 85/100: 100%|██████████| 59/59 [00:00<00:00, 70.03it/s]\n",
      "Epoch 86/100: 100%|██████████| 59/59 [00:00<00:00, 79.21it/s]\n",
      "Epoch 87/100: 100%|██████████| 59/59 [00:00<00:00, 87.56it/s]\n",
      "Epoch 88/100: 100%|██████████| 59/59 [00:00<00:00, 88.21it/s]\n",
      "Epoch 89/100: 100%|██████████| 59/59 [00:00<00:00, 88.35it/s]\n",
      "Epoch 90/100: 100%|██████████| 59/59 [00:00<00:00, 88.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0303\n",
      "Train Accuracy: 0.9968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 59/59 [00:00<00:00, 87.42it/s]\n",
      "Epoch 92/100: 100%|██████████| 59/59 [00:00<00:00, 87.42it/s]\n",
      "Epoch 93/100: 100%|██████████| 59/59 [00:00<00:00, 85.33it/s]\n",
      "Epoch 94/100: 100%|██████████| 59/59 [00:00<00:00, 85.67it/s]\n",
      "Epoch 95/100: 100%|██████████| 59/59 [00:00<00:00, 86.68it/s]\n",
      "Epoch 96/100: 100%|██████████| 59/59 [00:00<00:00, 86.67it/s]\n",
      "Epoch 97/100: 100%|██████████| 59/59 [00:00<00:00, 85.83it/s]\n",
      "Epoch 98/100: 100%|██████████| 59/59 [00:00<00:00, 85.90it/s]\n",
      "Epoch 99/100: 100%|██████████| 59/59 [00:00<00:00, 84.75it/s]\n",
      "Epoch 100/100: 100%|██████████| 59/59 [00:01<00:00, 37.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0299\n",
      "Train Accuracy: 0.9989\n",
      "Model trained and saved at descriptor_based_dnn.pth\n",
      "Accuracy on test set: 0.7554\n",
      "Cohen's Kappa: 0.5108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "train80 = pd.read_csv(\"train_data_80.csv\")\n",
    "train2O = pd.read_csv(\"train_data_20.csv\")\n",
    "X_80, smiles_list_80 = extract_selected_features(train80)\n",
    "X_20, smiles_list_20 = extract_selected_features(train2O)\n",
    "\n",
    "# Scale the data\n",
    "X_80 = StandardScaler().fit_transform(X_80)\n",
    "X_20 = StandardScaler().fit_transform(X_20)\n",
    "\n",
    "y_80 = train80['class']\n",
    "y_20 = train2O['class']\n",
    "\n",
    "# Split data\n",
    "X_train = X_80\n",
    "y_train = y_80\n",
    "X_test = X_20\n",
    "y_test = y_20\n",
    "\n",
    "# Model configuration\n",
    "config = {\n",
    "    \"input_size\": X_train.shape[1],\n",
    "    \"hidden_nodes\": 892,\n",
    "    \"hidden_layers\": 4,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_path\": \"descriptor_based_dnn.pth\"\n",
    "}\n",
    "\n",
    "# Initialize and train model\n",
    "model = DescriptorMLP(\n",
    "    config[\"input_size\"],\n",
    "    config[\"hidden_nodes\"],\n",
    "    config[\"hidden_layers\"],\n",
    "    config[\"dropout_rate\"]\n",
    ")\n",
    "train_params = {key: config[key] for key in [\"batch_size\", \"learning_rate\", \"epochs\", \"save_path\"]}\n",
    "model = train_dnn_with_dataloader(X_train, y_train, model, **train_params)\n",
    "# Predict on test set\n",
    "y_pred = predict_mlp(model, X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92eb6a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 236/236 [00:03<00:00, 67.28it/s]\n",
      "Epoch 2/100: 100%|██████████| 236/236 [00:03<00:00, 71.66it/s]\n",
      "Epoch 3/100: 100%|██████████| 236/236 [00:02<00:00, 92.34it/s]\n",
      "Epoch 4/100: 100%|██████████| 236/236 [00:02<00:00, 93.97it/s]\n",
      "Epoch 5/100: 100%|██████████| 236/236 [00:02<00:00, 92.19it/s]\n",
      "Epoch 6/100: 100%|██████████| 236/236 [00:02<00:00, 93.52it/s]\n",
      "Epoch 7/100: 100%|██████████| 236/236 [00:02<00:00, 94.52it/s]\n",
      "Epoch 8/100: 100%|██████████| 236/236 [00:02<00:00, 94.22it/s]\n",
      "Epoch 9/100: 100%|██████████| 236/236 [00:02<00:00, 91.66it/s]\n",
      "Epoch 10/100: 100%|██████████| 236/236 [00:02<00:00, 89.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3544\n",
      "Train Accuracy: 0.8841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 236/236 [00:02<00:00, 93.96it/s]\n",
      "Epoch 12/100: 100%|██████████| 236/236 [00:02<00:00, 93.01it/s]\n",
      "Epoch 13/100: 100%|██████████| 236/236 [00:02<00:00, 93.61it/s]\n",
      "Epoch 14/100: 100%|██████████| 236/236 [00:02<00:00, 93.55it/s]\n",
      "Epoch 15/100: 100%|██████████| 236/236 [00:02<00:00, 94.17it/s]\n",
      "Epoch 16/100: 100%|██████████| 236/236 [00:02<00:00, 91.39it/s]\n",
      "Epoch 17/100: 100%|██████████| 236/236 [00:02<00:00, 93.59it/s]\n",
      "Epoch 18/100: 100%|██████████| 236/236 [00:02<00:00, 91.00it/s]\n",
      "Epoch 19/100: 100%|██████████| 236/236 [00:02<00:00, 91.67it/s]\n",
      "Epoch 20/100: 100%|██████████| 236/236 [00:02<00:00, 93.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.2443\n",
      "Train Accuracy: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 236/236 [00:02<00:00, 92.85it/s]\n",
      "Epoch 22/100: 100%|██████████| 236/236 [00:02<00:00, 90.44it/s]\n",
      "Epoch 23/100: 100%|██████████| 236/236 [00:02<00:00, 93.47it/s]\n",
      "Epoch 24/100: 100%|██████████| 236/236 [00:02<00:00, 92.79it/s]\n",
      "Epoch 25/100: 100%|██████████| 236/236 [00:02<00:00, 93.96it/s]\n",
      "Epoch 26/100: 100%|██████████| 236/236 [00:02<00:00, 93.33it/s]\n",
      "Epoch 27/100: 100%|██████████| 236/236 [00:02<00:00, 91.12it/s]\n",
      "Epoch 28/100: 100%|██████████| 236/236 [00:02<00:00, 82.14it/s]\n",
      "Epoch 29/100: 100%|██████████| 236/236 [00:02<00:00, 87.34it/s]\n",
      "Epoch 30/100: 100%|██████████| 236/236 [00:02<00:00, 94.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.1781\n",
      "Train Accuracy: 0.9647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 236/236 [00:02<00:00, 93.16it/s]\n",
      "Epoch 32/100: 100%|██████████| 236/236 [00:02<00:00, 93.38it/s]\n",
      "Epoch 33/100: 100%|██████████| 236/236 [00:02<00:00, 94.91it/s]\n",
      "Epoch 34/100: 100%|██████████| 236/236 [00:02<00:00, 90.40it/s]\n",
      "Epoch 35/100: 100%|██████████| 236/236 [00:02<00:00, 82.54it/s]\n",
      "Epoch 36/100: 100%|██████████| 236/236 [00:02<00:00, 82.63it/s]\n",
      "Epoch 37/100: 100%|██████████| 236/236 [00:02<00:00, 91.29it/s]\n",
      "Epoch 38/100: 100%|██████████| 236/236 [00:02<00:00, 89.67it/s]\n",
      "Epoch 39/100: 100%|██████████| 236/236 [00:02<00:00, 90.87it/s]\n",
      "Epoch 40/100: 100%|██████████| 236/236 [00:02<00:00, 84.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.1440\n",
      "Train Accuracy: 0.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 236/236 [00:02<00:00, 92.17it/s]\n",
      "Epoch 42/100: 100%|██████████| 236/236 [00:02<00:00, 94.75it/s]\n",
      "Epoch 43/100: 100%|██████████| 236/236 [00:02<00:00, 93.17it/s]\n",
      "Epoch 44/100: 100%|██████████| 236/236 [00:02<00:00, 89.33it/s]\n",
      "Epoch 45/100: 100%|██████████| 236/236 [00:02<00:00, 89.85it/s]\n",
      "Epoch 46/100: 100%|██████████| 236/236 [00:02<00:00, 94.30it/s]\n",
      "Epoch 47/100: 100%|██████████| 236/236 [00:02<00:00, 93.25it/s]\n",
      "Epoch 48/100: 100%|██████████| 236/236 [00:02<00:00, 93.45it/s]\n",
      "Epoch 49/100: 100%|██████████| 236/236 [00:02<00:00, 93.72it/s]\n",
      "Epoch 50/100: 100%|██████████| 236/236 [00:02<00:00, 92.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.1191\n",
      "Train Accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 236/236 [00:02<00:00, 88.90it/s]\n",
      "Epoch 52/100: 100%|██████████| 236/236 [00:02<00:00, 93.12it/s]\n",
      "Epoch 53/100: 100%|██████████| 236/236 [00:02<00:00, 94.25it/s]\n",
      "Epoch 54/100: 100%|██████████| 236/236 [00:02<00:00, 94.43it/s]\n",
      "Epoch 55/100: 100%|██████████| 236/236 [00:02<00:00, 94.83it/s]\n",
      "Epoch 56/100: 100%|██████████| 236/236 [00:02<00:00, 93.18it/s]\n",
      "Epoch 57/100: 100%|██████████| 236/236 [00:02<00:00, 91.52it/s]\n",
      "Epoch 58/100: 100%|██████████| 236/236 [00:02<00:00, 94.40it/s]\n",
      "Epoch 59/100: 100%|██████████| 236/236 [00:02<00:00, 92.28it/s]\n",
      "Epoch 60/100: 100%|██████████| 236/236 [00:02<00:00, 93.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.0947\n",
      "Train Accuracy: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 236/236 [00:02<00:00, 93.30it/s]\n",
      "Epoch 62/100: 100%|██████████| 236/236 [00:02<00:00, 94.35it/s]\n",
      "Epoch 63/100: 100%|██████████| 236/236 [00:02<00:00, 90.02it/s]\n",
      "Epoch 64/100: 100%|██████████| 236/236 [00:02<00:00, 93.69it/s]\n",
      "Epoch 65/100: 100%|██████████| 236/236 [00:02<00:00, 94.14it/s]\n",
      "Epoch 66/100: 100%|██████████| 236/236 [00:02<00:00, 94.20it/s]\n",
      "Epoch 67/100: 100%|██████████| 236/236 [00:02<00:00, 94.58it/s]\n",
      "Epoch 68/100: 100%|██████████| 236/236 [00:02<00:00, 93.93it/s]\n",
      "Epoch 69/100: 100%|██████████| 236/236 [00:02<00:00, 93.12it/s]\n",
      "Epoch 70/100: 100%|██████████| 236/236 [00:02<00:00, 94.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0981\n",
      "Train Accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 236/236 [00:02<00:00, 92.63it/s]\n",
      "Epoch 72/100: 100%|██████████| 236/236 [00:02<00:00, 96.43it/s]\n",
      "Epoch 73/100: 100%|██████████| 236/236 [00:02<00:00, 95.09it/s]\n",
      "Epoch 74/100: 100%|██████████| 236/236 [00:02<00:00, 92.38it/s]\n",
      "Epoch 75/100: 100%|██████████| 236/236 [00:02<00:00, 91.01it/s]\n",
      "Epoch 76/100: 100%|██████████| 236/236 [00:02<00:00, 91.15it/s]\n",
      "Epoch 77/100: 100%|██████████| 236/236 [00:02<00:00, 89.45it/s]\n",
      "Epoch 78/100: 100%|██████████| 236/236 [00:02<00:00, 92.18it/s]\n",
      "Epoch 79/100: 100%|██████████| 236/236 [00:02<00:00, 90.73it/s]\n",
      "Epoch 80/100: 100%|██████████| 236/236 [00:02<00:00, 92.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0747\n",
      "Train Accuracy: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 236/236 [00:02<00:00, 91.66it/s]\n",
      "Epoch 82/100: 100%|██████████| 236/236 [00:02<00:00, 86.70it/s]\n",
      "Epoch 83/100: 100%|██████████| 236/236 [00:02<00:00, 87.77it/s]\n",
      "Epoch 84/100: 100%|██████████| 236/236 [00:02<00:00, 93.74it/s]\n",
      "Epoch 85/100: 100%|██████████| 236/236 [00:02<00:00, 94.21it/s]\n",
      "Epoch 86/100: 100%|██████████| 236/236 [00:02<00:00, 93.96it/s]\n",
      "Epoch 87/100: 100%|██████████| 236/236 [00:02<00:00, 93.97it/s]\n",
      "Epoch 88/100: 100%|██████████| 236/236 [00:02<00:00, 94.70it/s]\n",
      "Epoch 89/100: 100%|██████████| 236/236 [00:02<00:00, 92.80it/s]\n",
      "Epoch 90/100: 100%|██████████| 236/236 [00:02<00:00, 95.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0710\n",
      "Train Accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 236/236 [00:02<00:00, 96.47it/s]\n",
      "Epoch 92/100: 100%|██████████| 236/236 [00:02<00:00, 92.53it/s]\n",
      "Epoch 93/100: 100%|██████████| 236/236 [00:03<00:00, 76.00it/s]\n",
      "Epoch 94/100: 100%|██████████| 236/236 [00:02<00:00, 79.07it/s]\n",
      "Epoch 95/100: 100%|██████████| 236/236 [00:02<00:00, 78.80it/s]\n",
      "Epoch 96/100: 100%|██████████| 236/236 [00:02<00:00, 90.93it/s]\n",
      "Epoch 97/100: 100%|██████████| 236/236 [00:02<00:00, 92.91it/s]\n",
      "Epoch 98/100: 100%|██████████| 236/236 [00:02<00:00, 89.12it/s]\n",
      "Epoch 99/100: 100%|██████████| 236/236 [00:02<00:00, 93.36it/s]\n",
      "Epoch 100/100: 100%|██████████| 236/236 [00:02<00:00, 93.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0648\n",
      "Train Accuracy: 0.9926\n",
      "Model trained and saved at model_fold_0.pth\n",
      "Fold 1 - Accuracy: 0.7993, Kappa: 0.5980\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 236/236 [00:02<00:00, 89.98it/s]\n",
      "Epoch 2/100: 100%|██████████| 236/236 [00:02<00:00, 98.16it/s] \n",
      "Epoch 3/100: 100%|██████████| 236/236 [00:02<00:00, 99.43it/s] \n",
      "Epoch 4/100: 100%|██████████| 236/236 [00:02<00:00, 94.37it/s]\n",
      "Epoch 5/100: 100%|██████████| 236/236 [00:02<00:00, 90.72it/s]\n",
      "Epoch 6/100: 100%|██████████| 236/236 [00:04<00:00, 56.91it/s]\n",
      "Epoch 7/100: 100%|██████████| 236/236 [00:03<00:00, 62.45it/s]\n",
      "Epoch 8/100: 100%|██████████| 236/236 [00:03<00:00, 60.09it/s]\n",
      "Epoch 9/100: 100%|██████████| 236/236 [00:03<00:00, 63.93it/s]\n",
      "Epoch 10/100: 100%|██████████| 236/236 [00:03<00:00, 69.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3593\n",
      "Train Accuracy: 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 236/236 [00:02<00:00, 96.07it/s]\n",
      "Epoch 12/100: 100%|██████████| 236/236 [00:02<00:00, 86.47it/s]\n",
      "Epoch 13/100: 100%|██████████| 236/236 [00:03<00:00, 77.01it/s]\n",
      "Epoch 14/100: 100%|██████████| 236/236 [00:03<00:00, 71.77it/s]\n",
      "Epoch 15/100: 100%|██████████| 236/236 [00:02<00:00, 94.80it/s] \n",
      "Epoch 16/100: 100%|██████████| 236/236 [00:02<00:00, 97.25it/s]\n",
      "Epoch 17/100: 100%|██████████| 236/236 [00:02<00:00, 90.12it/s]\n",
      "Epoch 18/100: 100%|██████████| 236/236 [00:02<00:00, 85.06it/s]\n",
      "Epoch 19/100: 100%|██████████| 236/236 [00:02<00:00, 87.14it/s]\n",
      "Epoch 20/100: 100%|██████████| 236/236 [00:02<00:00, 80.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.2428\n",
      "Train Accuracy: 0.9408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 236/236 [00:02<00:00, 96.78it/s] \n",
      "Epoch 22/100: 100%|██████████| 236/236 [00:02<00:00, 97.14it/s]\n",
      "Epoch 23/100: 100%|██████████| 236/236 [00:02<00:00, 99.36it/s] \n",
      "Epoch 24/100: 100%|██████████| 236/236 [00:02<00:00, 99.86it/s] \n",
      "Epoch 25/100: 100%|██████████| 236/236 [00:02<00:00, 97.80it/s] \n",
      "Epoch 26/100: 100%|██████████| 236/236 [00:02<00:00, 97.85it/s] \n",
      "Epoch 27/100: 100%|██████████| 236/236 [00:02<00:00, 95.49it/s]\n",
      "Epoch 28/100: 100%|██████████| 236/236 [00:02<00:00, 99.58it/s] \n",
      "Epoch 29/100: 100%|██████████| 236/236 [00:02<00:00, 99.18it/s] \n",
      "Epoch 30/100: 100%|██████████| 236/236 [00:02<00:00, 98.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.1847\n",
      "Train Accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 236/236 [00:02<00:00, 98.30it/s] \n",
      "Epoch 32/100: 100%|██████████| 236/236 [00:02<00:00, 97.49it/s]\n",
      "Epoch 33/100: 100%|██████████| 236/236 [00:02<00:00, 98.48it/s]\n",
      "Epoch 34/100: 100%|██████████| 236/236 [00:02<00:00, 96.76it/s]\n",
      "Epoch 35/100: 100%|██████████| 236/236 [00:02<00:00, 98.27it/s]\n",
      "Epoch 36/100: 100%|██████████| 236/236 [00:02<00:00, 95.61it/s]\n",
      "Epoch 37/100: 100%|██████████| 236/236 [00:02<00:00, 97.71it/s]\n",
      "Epoch 38/100: 100%|██████████| 236/236 [00:02<00:00, 96.83it/s]\n",
      "Epoch 39/100: 100%|██████████| 236/236 [00:02<00:00, 98.45it/s] \n",
      "Epoch 40/100: 100%|██████████| 236/236 [00:02<00:00, 98.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.1514\n",
      "Train Accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 236/236 [00:02<00:00, 96.71it/s]\n",
      "Epoch 42/100: 100%|██████████| 236/236 [00:02<00:00, 94.98it/s]\n",
      "Epoch 43/100: 100%|██████████| 236/236 [00:02<00:00, 92.20it/s]\n",
      "Epoch 44/100: 100%|██████████| 236/236 [00:02<00:00, 97.66it/s]\n",
      "Epoch 45/100: 100%|██████████| 236/236 [00:02<00:00, 84.34it/s]\n",
      "Epoch 46/100: 100%|██████████| 236/236 [00:02<00:00, 96.29it/s]\n",
      "Epoch 47/100: 100%|██████████| 236/236 [00:02<00:00, 97.37it/s]\n",
      "Epoch 48/100: 100%|██████████| 236/236 [00:02<00:00, 90.47it/s]\n",
      "Epoch 49/100: 100%|██████████| 236/236 [00:02<00:00, 97.84it/s] \n",
      "Epoch 50/100: 100%|██████████| 236/236 [00:02<00:00, 96.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.1222\n",
      "Train Accuracy: 0.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 236/236 [00:02<00:00, 97.87it/s] \n",
      "Epoch 52/100: 100%|██████████| 236/236 [00:02<00:00, 99.66it/s] \n",
      "Epoch 53/100: 100%|██████████| 236/236 [00:02<00:00, 90.30it/s]\n",
      "Epoch 54/100: 100%|██████████| 236/236 [00:02<00:00, 96.40it/s] \n",
      "Epoch 55/100: 100%|██████████| 236/236 [00:02<00:00, 98.94it/s]\n",
      "Epoch 56/100: 100%|██████████| 236/236 [00:02<00:00, 98.86it/s] \n",
      "Epoch 57/100: 100%|██████████| 236/236 [00:02<00:00, 98.48it/s]\n",
      "Epoch 58/100: 100%|██████████| 236/236 [00:02<00:00, 99.18it/s] \n",
      "Epoch 59/100: 100%|██████████| 236/236 [00:02<00:00, 99.22it/s] \n",
      "Epoch 60/100: 100%|██████████| 236/236 [00:02<00:00, 98.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.1030\n",
      "Train Accuracy: 0.9809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 236/236 [00:02<00:00, 99.13it/s]\n",
      "Epoch 62/100: 100%|██████████| 236/236 [00:02<00:00, 96.53it/s]\n",
      "Epoch 63/100: 100%|██████████| 236/236 [00:02<00:00, 94.79it/s] \n",
      "Epoch 64/100: 100%|██████████| 236/236 [00:02<00:00, 98.91it/s]\n",
      "Epoch 65/100: 100%|██████████| 236/236 [00:02<00:00, 99.01it/s] \n",
      "Epoch 66/100: 100%|██████████| 236/236 [00:02<00:00, 99.24it/s] \n",
      "Epoch 67/100: 100%|██████████| 236/236 [00:02<00:00, 93.27it/s] \n",
      "Epoch 68/100: 100%|██████████| 236/236 [00:02<00:00, 94.22it/s] \n",
      "Epoch 69/100: 100%|██████████| 236/236 [00:02<00:00, 93.32it/s]\n",
      "Epoch 70/100: 100%|██████████| 236/236 [00:02<00:00, 94.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0862\n",
      "Train Accuracy: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 236/236 [00:02<00:00, 97.83it/s]\n",
      "Epoch 72/100: 100%|██████████| 236/236 [00:02<00:00, 97.00it/s]\n",
      "Epoch 73/100: 100%|██████████| 236/236 [00:02<00:00, 98.83it/s]\n",
      "Epoch 74/100: 100%|██████████| 236/236 [00:02<00:00, 98.55it/s] \n",
      "Epoch 75/100: 100%|██████████| 236/236 [00:02<00:00, 97.24it/s] \n",
      "Epoch 76/100: 100%|██████████| 236/236 [00:02<00:00, 98.08it/s] \n",
      "Epoch 77/100: 100%|██████████| 236/236 [00:02<00:00, 96.96it/s] \n",
      "Epoch 78/100: 100%|██████████| 236/236 [00:02<00:00, 99.91it/s] \n",
      "Epoch 79/100: 100%|██████████| 236/236 [00:02<00:00, 99.57it/s] \n",
      "Epoch 80/100: 100%|██████████| 236/236 [00:02<00:00, 99.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0779\n",
      "Train Accuracy: 0.9882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 236/236 [00:02<00:00, 98.82it/s] \n",
      "Epoch 82/100: 100%|██████████| 236/236 [00:02<00:00, 99.46it/s] \n",
      "Epoch 83/100: 100%|██████████| 236/236 [00:02<00:00, 97.24it/s] \n",
      "Epoch 84/100: 100%|██████████| 236/236 [00:02<00:00, 99.56it/s] \n",
      "Epoch 85/100: 100%|██████████| 236/236 [00:02<00:00, 98.66it/s] \n",
      "Epoch 86/100: 100%|██████████| 236/236 [00:02<00:00, 99.13it/s] \n",
      "Epoch 87/100: 100%|██████████| 236/236 [00:02<00:00, 99.04it/s] \n",
      "Epoch 88/100: 100%|██████████| 236/236 [00:02<00:00, 99.23it/s] \n",
      "Epoch 89/100: 100%|██████████| 236/236 [00:02<00:00, 96.66it/s] \n",
      "Epoch 90/100: 100%|██████████| 236/236 [00:02<00:00, 91.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0707\n",
      "Train Accuracy: 0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 236/236 [00:02<00:00, 98.48it/s] \n",
      "Epoch 92/100: 100%|██████████| 236/236 [00:02<00:00, 91.99it/s]\n",
      "Epoch 93/100: 100%|██████████| 236/236 [00:02<00:00, 99.21it/s] \n",
      "Epoch 94/100: 100%|██████████| 236/236 [00:02<00:00, 97.55it/s]\n",
      "Epoch 95/100: 100%|██████████| 236/236 [00:02<00:00, 94.68it/s] \n",
      "Epoch 96/100: 100%|██████████| 236/236 [00:02<00:00, 97.17it/s]\n",
      "Epoch 97/100: 100%|██████████| 236/236 [00:02<00:00, 98.79it/s] \n",
      "Epoch 98/100: 100%|██████████| 236/236 [00:02<00:00, 98.28it/s]\n",
      "Epoch 99/100: 100%|██████████| 236/236 [00:02<00:00, 94.62it/s]\n",
      "Epoch 100/100: 100%|██████████| 236/236 [00:02<00:00, 98.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0663\n",
      "Train Accuracy: 0.9934\n",
      "Model trained and saved at model_fold_1.pth\n",
      "Fold 2 - Accuracy: 0.8014, Kappa: 0.6030\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 236/236 [00:02<00:00, 92.02it/s] \n",
      "Epoch 2/100: 100%|██████████| 236/236 [00:02<00:00, 97.90it/s]\n",
      "Epoch 3/100: 100%|██████████| 236/236 [00:02<00:00, 98.87it/s] \n",
      "Epoch 4/100: 100%|██████████| 236/236 [00:02<00:00, 99.31it/s] \n",
      "Epoch 5/100: 100%|██████████| 236/236 [00:02<00:00, 81.08it/s]\n",
      "Epoch 6/100: 100%|██████████| 236/236 [00:03<00:00, 60.12it/s]\n",
      "Epoch 7/100: 100%|██████████| 236/236 [00:03<00:00, 61.37it/s]\n",
      "Epoch 8/100: 100%|██████████| 236/236 [00:04<00:00, 54.30it/s]\n",
      "Epoch 9/100: 100%|██████████| 236/236 [00:03<00:00, 69.34it/s]\n",
      "Epoch 10/100: 100%|██████████| 236/236 [00:04<00:00, 58.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3623\n",
      "Train Accuracy: 0.8765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 236/236 [00:02<00:00, 93.24it/s]\n",
      "Epoch 12/100: 100%|██████████| 236/236 [00:02<00:00, 97.60it/s] \n",
      "Epoch 13/100: 100%|██████████| 236/236 [00:02<00:00, 92.98it/s]\n",
      "Epoch 14/100: 100%|██████████| 236/236 [00:02<00:00, 94.77it/s]\n",
      "Epoch 15/100: 100%|██████████| 236/236 [00:02<00:00, 99.30it/s] \n",
      "Epoch 16/100: 100%|██████████| 236/236 [00:02<00:00, 97.92it/s]\n",
      "Epoch 17/100: 100%|██████████| 236/236 [00:02<00:00, 98.75it/s] \n",
      "Epoch 18/100: 100%|██████████| 236/236 [00:02<00:00, 95.83it/s]\n",
      "Epoch 19/100: 100%|██████████| 236/236 [00:02<00:00, 98.14it/s]\n",
      "Epoch 20/100: 100%|██████████| 236/236 [00:02<00:00, 95.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.2541\n",
      "Train Accuracy: 0.9376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 236/236 [00:02<00:00, 96.86it/s] \n",
      "Epoch 22/100: 100%|██████████| 236/236 [00:02<00:00, 98.53it/s]\n",
      "Epoch 23/100: 100%|██████████| 236/236 [00:02<00:00, 98.48it/s]\n",
      "Epoch 24/100: 100%|██████████| 236/236 [00:02<00:00, 97.49it/s]\n",
      "Epoch 25/100: 100%|██████████| 236/236 [00:02<00:00, 96.23it/s]\n",
      "Epoch 26/100: 100%|██████████| 236/236 [00:02<00:00, 98.02it/s]\n",
      "Epoch 27/100: 100%|██████████| 236/236 [00:02<00:00, 98.20it/s]\n",
      "Epoch 28/100: 100%|██████████| 236/236 [00:02<00:00, 96.19it/s]\n",
      "Epoch 29/100: 100%|██████████| 236/236 [00:02<00:00, 97.77it/s]\n",
      "Epoch 30/100: 100%|██████████| 236/236 [00:02<00:00, 97.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.1901\n",
      "Train Accuracy: 0.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 236/236 [00:02<00:00, 94.40it/s]\n",
      "Epoch 32/100: 100%|██████████| 236/236 [00:02<00:00, 94.83it/s]\n",
      "Epoch 33/100: 100%|██████████| 236/236 [00:02<00:00, 96.63it/s]\n",
      "Epoch 34/100: 100%|██████████| 236/236 [00:02<00:00, 97.51it/s]\n",
      "Epoch 35/100: 100%|██████████| 236/236 [00:02<00:00, 98.65it/s] \n",
      "Epoch 36/100: 100%|██████████| 236/236 [00:02<00:00, 98.09it/s]\n",
      "Epoch 37/100: 100%|██████████| 236/236 [00:02<00:00, 98.06it/s]\n",
      "Epoch 38/100: 100%|██████████| 236/236 [00:02<00:00, 95.36it/s]\n",
      "Epoch 39/100: 100%|██████████| 236/236 [00:02<00:00, 95.33it/s]\n",
      "Epoch 40/100: 100%|██████████| 236/236 [00:02<00:00, 98.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.1475\n",
      "Train Accuracy: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 236/236 [00:02<00:00, 98.68it/s] \n",
      "Epoch 42/100: 100%|██████████| 236/236 [00:02<00:00, 98.58it/s] \n",
      "Epoch 43/100: 100%|██████████| 236/236 [00:02<00:00, 99.83it/s] \n",
      "Epoch 44/100: 100%|██████████| 236/236 [00:02<00:00, 99.02it/s]\n",
      "Epoch 45/100: 100%|██████████| 236/236 [00:02<00:00, 96.38it/s]\n",
      "Epoch 46/100: 100%|██████████| 236/236 [00:02<00:00, 97.11it/s] \n",
      "Epoch 47/100: 100%|██████████| 236/236 [00:02<00:00, 98.95it/s] \n",
      "Epoch 48/100: 100%|██████████| 236/236 [00:02<00:00, 99.39it/s] \n",
      "Epoch 49/100: 100%|██████████| 236/236 [00:02<00:00, 99.42it/s] \n",
      "Epoch 50/100: 100%|██████████| 236/236 [00:02<00:00, 99.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.1236\n",
      "Train Accuracy: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 236/236 [00:02<00:00, 99.27it/s] \n",
      "Epoch 52/100: 100%|██████████| 236/236 [00:02<00:00, 99.01it/s] \n",
      "Epoch 53/100: 100%|██████████| 236/236 [00:02<00:00, 99.41it/s] \n",
      "Epoch 54/100: 100%|██████████| 236/236 [00:02<00:00, 96.08it/s]\n",
      "Epoch 55/100: 100%|██████████| 236/236 [00:02<00:00, 99.03it/s] \n",
      "Epoch 56/100: 100%|██████████| 236/236 [00:02<00:00, 98.80it/s] \n",
      "Epoch 57/100: 100%|██████████| 236/236 [00:02<00:00, 99.28it/s] \n",
      "Epoch 58/100: 100%|██████████| 236/236 [00:02<00:00, 98.79it/s] \n",
      "Epoch 59/100: 100%|██████████| 236/236 [00:02<00:00, 100.19it/s]\n",
      "Epoch 60/100: 100%|██████████| 236/236 [00:02<00:00, 99.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.1024\n",
      "Train Accuracy: 0.9797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 236/236 [00:02<00:00, 96.90it/s]\n",
      "Epoch 62/100: 100%|██████████| 236/236 [00:02<00:00, 98.74it/s]\n",
      "Epoch 63/100: 100%|██████████| 236/236 [00:02<00:00, 92.65it/s]\n",
      "Epoch 64/100: 100%|██████████| 236/236 [00:02<00:00, 99.03it/s] \n",
      "Epoch 65/100: 100%|██████████| 236/236 [00:02<00:00, 100.03it/s]\n",
      "Epoch 66/100: 100%|██████████| 236/236 [00:02<00:00, 99.42it/s] \n",
      "Epoch 67/100: 100%|██████████| 236/236 [00:02<00:00, 98.85it/s] \n",
      "Epoch 68/100: 100%|██████████| 236/236 [00:02<00:00, 99.15it/s] \n",
      "Epoch 69/100: 100%|██████████| 236/236 [00:02<00:00, 96.54it/s]\n",
      "Epoch 70/100: 100%|██████████| 236/236 [00:02<00:00, 96.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0863\n",
      "Train Accuracy: 0.9861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 236/236 [00:02<00:00, 98.69it/s] \n",
      "Epoch 72/100: 100%|██████████| 236/236 [00:02<00:00, 97.52it/s]\n",
      "Epoch 73/100: 100%|██████████| 236/236 [00:02<00:00, 98.60it/s] \n",
      "Epoch 74/100: 100%|██████████| 236/236 [00:02<00:00, 98.33it/s]\n",
      "Epoch 75/100: 100%|██████████| 236/236 [00:02<00:00, 98.68it/s]\n",
      "Epoch 76/100: 100%|██████████| 236/236 [00:02<00:00, 96.62it/s] \n",
      "Epoch 77/100: 100%|██████████| 236/236 [00:02<00:00, 98.18it/s]\n",
      "Epoch 78/100: 100%|██████████| 236/236 [00:02<00:00, 98.83it/s]\n",
      "Epoch 79/100: 100%|██████████| 236/236 [00:02<00:00, 98.85it/s]\n",
      "Epoch 80/100: 100%|██████████| 236/236 [00:02<00:00, 99.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0784\n",
      "Train Accuracy: 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 236/236 [00:02<00:00, 98.72it/s]\n",
      "Epoch 82/100: 100%|██████████| 236/236 [00:02<00:00, 99.33it/s] \n",
      "Epoch 83/100: 100%|██████████| 236/236 [00:02<00:00, 90.64it/s]\n",
      "Epoch 84/100: 100%|██████████| 236/236 [00:02<00:00, 97.01it/s]\n",
      "Epoch 85/100: 100%|██████████| 236/236 [00:02<00:00, 99.09it/s] \n",
      "Epoch 86/100: 100%|██████████| 236/236 [00:02<00:00, 100.32it/s]\n",
      "Epoch 87/100: 100%|██████████| 236/236 [00:02<00:00, 98.78it/s] \n",
      "Epoch 88/100: 100%|██████████| 236/236 [00:02<00:00, 96.89it/s] \n",
      "Epoch 89/100: 100%|██████████| 236/236 [00:02<00:00, 96.21it/s] \n",
      "Epoch 90/100: 100%|██████████| 236/236 [00:02<00:00, 99.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0748\n",
      "Train Accuracy: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 236/236 [00:02<00:00, 98.25it/s] \n",
      "Epoch 92/100: 100%|██████████| 236/236 [00:02<00:00, 98.70it/s] \n",
      "Epoch 93/100: 100%|██████████| 236/236 [00:02<00:00, 99.28it/s] \n",
      "Epoch 94/100: 100%|██████████| 236/236 [00:02<00:00, 100.36it/s]\n",
      "Epoch 95/100: 100%|██████████| 236/236 [00:02<00:00, 97.54it/s] \n",
      "Epoch 96/100: 100%|██████████| 236/236 [00:02<00:00, 97.57it/s] \n",
      "Epoch 97/100: 100%|██████████| 236/236 [00:02<00:00, 99.21it/s] \n",
      "Epoch 98/100: 100%|██████████| 236/236 [00:02<00:00, 99.59it/s] \n",
      "Epoch 99/100: 100%|██████████| 236/236 [00:02<00:00, 99.34it/s] \n",
      "Epoch 100/100: 100%|██████████| 236/236 [00:02<00:00, 99.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0658\n",
      "Train Accuracy: 0.9908\n",
      "Model trained and saved at model_fold_2.pth\n",
      "Fold 3 - Accuracy: 0.8136, Kappa: 0.6272\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 236/236 [00:02<00:00, 102.42it/s]\n",
      "Epoch 2/100: 100%|██████████| 236/236 [00:02<00:00, 100.68it/s]\n",
      "Epoch 3/100: 100%|██████████| 236/236 [00:02<00:00, 104.00it/s]\n",
      "Epoch 4/100: 100%|██████████| 236/236 [00:02<00:00, 105.24it/s]\n",
      "Epoch 5/100: 100%|██████████| 236/236 [00:02<00:00, 104.44it/s]\n",
      "Epoch 6/100: 100%|██████████| 236/236 [00:03<00:00, 71.05it/s]\n",
      "Epoch 7/100: 100%|██████████| 236/236 [00:03<00:00, 64.94it/s]\n",
      "Epoch 8/100: 100%|██████████| 236/236 [00:03<00:00, 65.35it/s]\n",
      "Epoch 9/100: 100%|██████████| 236/236 [00:03<00:00, 62.24it/s]\n",
      "Epoch 10/100: 100%|██████████| 236/236 [00:02<00:00, 78.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3592\n",
      "Train Accuracy: 0.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 236/236 [00:02<00:00, 84.18it/s] \n",
      "Epoch 12/100: 100%|██████████| 236/236 [00:02<00:00, 102.58it/s]\n",
      "Epoch 13/100: 100%|██████████| 236/236 [00:02<00:00, 103.74it/s]\n",
      "Epoch 14/100: 100%|██████████| 236/236 [00:02<00:00, 102.22it/s]\n",
      "Epoch 15/100: 100%|██████████| 236/236 [00:02<00:00, 99.03it/s] \n",
      "Epoch 16/100: 100%|██████████| 236/236 [00:02<00:00, 103.25it/s]\n",
      "Epoch 17/100: 100%|██████████| 236/236 [00:02<00:00, 103.08it/s]\n",
      "Epoch 18/100: 100%|██████████| 236/236 [00:02<00:00, 100.45it/s]\n",
      "Epoch 19/100: 100%|██████████| 236/236 [00:02<00:00, 100.63it/s]\n",
      "Epoch 20/100: 100%|██████████| 236/236 [00:02<00:00, 101.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.2437\n",
      "Train Accuracy: 0.9389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 236/236 [00:02<00:00, 102.18it/s]\n",
      "Epoch 22/100: 100%|██████████| 236/236 [00:02<00:00, 103.18it/s]\n",
      "Epoch 23/100: 100%|██████████| 236/236 [00:02<00:00, 100.25it/s]\n",
      "Epoch 24/100: 100%|██████████| 236/236 [00:02<00:00, 103.88it/s]\n",
      "Epoch 25/100: 100%|██████████| 236/236 [00:02<00:00, 104.13it/s]\n",
      "Epoch 26/100: 100%|██████████| 236/236 [00:02<00:00, 105.05it/s]\n",
      "Epoch 27/100: 100%|██████████| 236/236 [00:02<00:00, 104.12it/s]\n",
      "Epoch 28/100: 100%|██████████| 236/236 [00:02<00:00, 103.03it/s]\n",
      "Epoch 29/100: 100%|██████████| 236/236 [00:02<00:00, 102.90it/s]\n",
      "Epoch 30/100: 100%|██████████| 236/236 [00:02<00:00, 95.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.1823\n",
      "Train Accuracy: 0.9665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 236/236 [00:02<00:00, 83.60it/s] \n",
      "Epoch 32/100: 100%|██████████| 236/236 [00:02<00:00, 107.86it/s]\n",
      "Epoch 33/100: 100%|██████████| 236/236 [00:02<00:00, 103.36it/s]\n",
      "Epoch 34/100: 100%|██████████| 236/236 [00:02<00:00, 103.45it/s]\n",
      "Epoch 35/100: 100%|██████████| 236/236 [00:02<00:00, 103.11it/s]\n",
      "Epoch 36/100: 100%|██████████| 236/236 [00:02<00:00, 100.62it/s]\n",
      "Epoch 37/100: 100%|██████████| 236/236 [00:02<00:00, 103.82it/s]\n",
      "Epoch 38/100: 100%|██████████| 236/236 [00:02<00:00, 99.13it/s] \n",
      "Epoch 39/100: 100%|██████████| 236/236 [00:02<00:00, 100.59it/s]\n",
      "Epoch 40/100: 100%|██████████| 236/236 [00:02<00:00, 103.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.1401\n",
      "Train Accuracy: 0.9753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 236/236 [00:02<00:00, 102.93it/s]\n",
      "Epoch 42/100: 100%|██████████| 236/236 [00:02<00:00, 105.57it/s]\n",
      "Epoch 43/100: 100%|██████████| 236/236 [00:02<00:00, 103.21it/s]\n",
      "Epoch 44/100: 100%|██████████| 236/236 [00:02<00:00, 103.50it/s]\n",
      "Epoch 45/100: 100%|██████████| 236/236 [00:02<00:00, 102.81it/s]\n",
      "Epoch 46/100: 100%|██████████| 236/236 [00:02<00:00, 102.24it/s]\n",
      "Epoch 47/100: 100%|██████████| 236/236 [00:02<00:00, 100.88it/s]\n",
      "Epoch 48/100: 100%|██████████| 236/236 [00:02<00:00, 100.74it/s]\n",
      "Epoch 49/100: 100%|██████████| 236/236 [00:02<00:00, 95.81it/s] \n",
      "Epoch 50/100: 100%|██████████| 236/236 [00:04<00:00, 50.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.1141\n",
      "Train Accuracy: 0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 236/236 [00:02<00:00, 81.96it/s]\n",
      "Epoch 52/100: 100%|██████████| 236/236 [00:03<00:00, 71.85it/s]\n",
      "Epoch 53/100: 100%|██████████| 236/236 [00:02<00:00, 82.11it/s]\n",
      "Epoch 54/100: 100%|██████████| 236/236 [00:02<00:00, 84.48it/s]\n",
      "Epoch 55/100: 100%|██████████| 236/236 [00:02<00:00, 92.30it/s]\n",
      "Epoch 56/100: 100%|██████████| 236/236 [00:02<00:00, 87.18it/s]\n",
      "Epoch 57/100: 100%|██████████| 236/236 [00:02<00:00, 93.77it/s]\n",
      "Epoch 58/100: 100%|██████████| 236/236 [00:02<00:00, 95.36it/s]\n",
      "Epoch 59/100: 100%|██████████| 236/236 [00:02<00:00, 88.15it/s]\n",
      "Epoch 60/100: 100%|██████████| 236/236 [00:02<00:00, 81.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.1020\n",
      "Train Accuracy: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 236/236 [00:02<00:00, 86.05it/s]\n",
      "Epoch 62/100: 100%|██████████| 236/236 [00:02<00:00, 97.20it/s]\n",
      "Epoch 63/100: 100%|██████████| 236/236 [00:02<00:00, 97.93it/s]\n",
      "Epoch 64/100: 100%|██████████| 236/236 [00:02<00:00, 95.58it/s]\n",
      "Epoch 65/100: 100%|██████████| 236/236 [00:02<00:00, 97.96it/s] \n",
      "Epoch 66/100: 100%|██████████| 236/236 [00:02<00:00, 94.78it/s] \n",
      "Epoch 67/100: 100%|██████████| 236/236 [00:02<00:00, 97.29it/s]\n",
      "Epoch 68/100: 100%|██████████| 236/236 [00:02<00:00, 95.40it/s]\n",
      "Epoch 69/100: 100%|██████████| 236/236 [00:02<00:00, 96.42it/s]\n",
      "Epoch 70/100: 100%|██████████| 236/236 [00:02<00:00, 94.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0853\n",
      "Train Accuracy: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 236/236 [00:02<00:00, 97.83it/s]\n",
      "Epoch 72/100: 100%|██████████| 236/236 [00:02<00:00, 96.06it/s] \n",
      "Epoch 73/100: 100%|██████████| 236/236 [00:02<00:00, 95.98it/s]\n",
      "Epoch 74/100: 100%|██████████| 236/236 [00:02<00:00, 94.21it/s]\n",
      "Epoch 75/100: 100%|██████████| 236/236 [00:02<00:00, 98.70it/s] \n",
      "Epoch 76/100: 100%|██████████| 236/236 [00:02<00:00, 92.66it/s]\n",
      "Epoch 77/100: 100%|██████████| 236/236 [00:02<00:00, 94.63it/s]\n",
      "Epoch 78/100: 100%|██████████| 236/236 [00:02<00:00, 96.99it/s]\n",
      "Epoch 79/100: 100%|██████████| 236/236 [00:02<00:00, 99.21it/s]\n",
      "Epoch 80/100: 100%|██████████| 236/236 [00:02<00:00, 98.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0747\n",
      "Train Accuracy: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 236/236 [00:02<00:00, 93.11it/s]\n",
      "Epoch 82/100: 100%|██████████| 236/236 [00:02<00:00, 96.99it/s]\n",
      "Epoch 83/100: 100%|██████████| 236/236 [00:02<00:00, 92.65it/s]\n",
      "Epoch 84/100: 100%|██████████| 236/236 [00:02<00:00, 92.08it/s]\n",
      "Epoch 85/100: 100%|██████████| 236/236 [00:02<00:00, 97.32it/s]\n",
      "Epoch 86/100: 100%|██████████| 236/236 [00:02<00:00, 98.81it/s] \n",
      "Epoch 87/100: 100%|██████████| 236/236 [00:02<00:00, 99.14it/s] \n",
      "Epoch 88/100: 100%|██████████| 236/236 [00:02<00:00, 95.48it/s] \n",
      "Epoch 89/100: 100%|██████████| 236/236 [00:02<00:00, 97.64it/s]\n",
      "Epoch 90/100: 100%|██████████| 236/236 [00:02<00:00, 95.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0698\n",
      "Train Accuracy: 0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 236/236 [00:02<00:00, 95.70it/s]\n",
      "Epoch 92/100: 100%|██████████| 236/236 [00:02<00:00, 97.56it/s]\n",
      "Epoch 93/100: 100%|██████████| 236/236 [00:02<00:00, 97.44it/s]\n",
      "Epoch 94/100: 100%|██████████| 236/236 [00:02<00:00, 96.39it/s]\n",
      "Epoch 95/100: 100%|██████████| 236/236 [00:02<00:00, 97.87it/s]\n",
      "Epoch 96/100: 100%|██████████| 236/236 [00:02<00:00, 96.72it/s]\n",
      "Epoch 97/100: 100%|██████████| 236/236 [00:02<00:00, 95.79it/s]\n",
      "Epoch 98/100: 100%|██████████| 236/236 [00:02<00:00, 97.11it/s]\n",
      "Epoch 99/100: 100%|██████████| 236/236 [00:02<00:00, 96.65it/s]\n",
      "Epoch 100/100: 100%|██████████| 236/236 [00:02<00:00, 97.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0591\n",
      "Train Accuracy: 0.9911\n",
      "Model trained and saved at model_fold_3.pth\n",
      "Fold 4 - Accuracy: 0.8072, Kappa: 0.6147\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 236/236 [00:02<00:00, 99.25it/s] \n",
      "Epoch 2/100: 100%|██████████| 236/236 [00:02<00:00, 99.55it/s] \n",
      "Epoch 3/100: 100%|██████████| 236/236 [00:02<00:00, 98.50it/s] \n",
      "Epoch 4/100: 100%|██████████| 236/236 [00:02<00:00, 98.85it/s] \n",
      "Epoch 5/100: 100%|██████████| 236/236 [00:03<00:00, 61.30it/s]\n",
      "Epoch 6/100: 100%|██████████| 236/236 [00:04<00:00, 56.36it/s]\n",
      "Epoch 7/100: 100%|██████████| 236/236 [00:04<00:00, 56.33it/s]\n",
      "Epoch 8/100: 100%|██████████| 236/236 [00:04<00:00, 57.11it/s]\n",
      "Epoch 9/100: 100%|██████████| 236/236 [00:03<00:00, 74.42it/s]\n",
      "Epoch 10/100: 100%|██████████| 236/236 [00:02<00:00, 97.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3617\n",
      "Train Accuracy: 0.8836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 236/236 [00:02<00:00, 96.42it/s] \n",
      "Epoch 12/100: 100%|██████████| 236/236 [00:02<00:00, 96.84it/s] \n",
      "Epoch 13/100: 100%|██████████| 236/236 [00:02<00:00, 99.23it/s] \n",
      "Epoch 14/100: 100%|██████████| 236/236 [00:02<00:00, 98.13it/s]\n",
      "Epoch 15/100: 100%|██████████| 236/236 [00:02<00:00, 99.96it/s] \n",
      "Epoch 16/100: 100%|██████████| 236/236 [00:02<00:00, 99.47it/s] \n",
      "Epoch 17/100: 100%|██████████| 236/236 [00:02<00:00, 86.10it/s] \n",
      "Epoch 18/100: 100%|██████████| 236/236 [00:02<00:00, 96.93it/s]\n",
      "Epoch 19/100: 100%|██████████| 236/236 [00:02<00:00, 100.54it/s]\n",
      "Epoch 20/100: 100%|██████████| 236/236 [00:02<00:00, 96.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.2466\n",
      "Train Accuracy: 0.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 236/236 [00:02<00:00, 100.07it/s]\n",
      "Epoch 22/100: 100%|██████████| 236/236 [00:02<00:00, 98.65it/s] \n",
      "Epoch 23/100: 100%|██████████| 236/236 [00:02<00:00, 98.68it/s] \n",
      "Epoch 24/100: 100%|██████████| 236/236 [00:03<00:00, 66.77it/s]\n",
      "Epoch 25/100: 100%|██████████| 236/236 [00:02<00:00, 81.27it/s]\n",
      "Epoch 26/100: 100%|██████████| 236/236 [00:02<00:00, 85.54it/s]\n",
      "Epoch 27/100: 100%|██████████| 236/236 [00:02<00:00, 89.50it/s]\n",
      "Epoch 28/100: 100%|██████████| 236/236 [00:02<00:00, 96.10it/s]\n",
      "Epoch 29/100: 100%|██████████| 236/236 [00:02<00:00, 87.89it/s]\n",
      "Epoch 30/100: 100%|██████████| 236/236 [00:02<00:00, 89.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.1749\n",
      "Train Accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 236/236 [00:02<00:00, 90.50it/s]\n",
      "Epoch 32/100: 100%|██████████| 236/236 [00:02<00:00, 94.63it/s]\n",
      "Epoch 33/100: 100%|██████████| 236/236 [00:02<00:00, 95.75it/s]\n",
      "Epoch 34/100: 100%|██████████| 236/236 [00:02<00:00, 93.23it/s]\n",
      "Epoch 35/100: 100%|██████████| 236/236 [00:02<00:00, 90.38it/s]\n",
      "Epoch 36/100: 100%|██████████| 236/236 [00:02<00:00, 94.18it/s]\n",
      "Epoch 37/100: 100%|██████████| 236/236 [00:02<00:00, 95.37it/s]\n",
      "Epoch 38/100: 100%|██████████| 236/236 [00:02<00:00, 90.14it/s]\n",
      "Epoch 39/100: 100%|██████████| 236/236 [00:02<00:00, 94.42it/s]\n",
      "Epoch 40/100: 100%|██████████| 236/236 [00:02<00:00, 95.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.1422\n",
      "Train Accuracy: 0.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 236/236 [00:03<00:00, 76.02it/s]\n",
      "Epoch 42/100: 100%|██████████| 236/236 [00:02<00:00, 90.44it/s]\n",
      "Epoch 43/100: 100%|██████████| 236/236 [00:02<00:00, 93.18it/s]\n",
      "Epoch 44/100: 100%|██████████| 236/236 [00:02<00:00, 90.05it/s]\n",
      "Epoch 45/100: 100%|██████████| 236/236 [00:02<00:00, 92.40it/s]\n",
      "Epoch 46/100: 100%|██████████| 236/236 [00:02<00:00, 90.51it/s]\n",
      "Epoch 47/100: 100%|██████████| 236/236 [00:02<00:00, 90.43it/s]\n",
      "Epoch 48/100: 100%|██████████| 236/236 [00:02<00:00, 87.81it/s]\n",
      "Epoch 49/100: 100%|██████████| 236/236 [00:02<00:00, 87.19it/s]\n",
      "Epoch 50/100: 100%|██████████| 236/236 [00:02<00:00, 85.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.1180\n",
      "Train Accuracy: 0.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 236/236 [00:02<00:00, 87.01it/s]\n",
      "Epoch 52/100: 100%|██████████| 236/236 [00:03<00:00, 78.65it/s]\n",
      "Epoch 53/100: 100%|██████████| 236/236 [00:02<00:00, 96.02it/s]\n",
      "Epoch 54/100: 100%|██████████| 236/236 [00:02<00:00, 89.88it/s]\n",
      "Epoch 55/100: 100%|██████████| 236/236 [00:02<00:00, 94.03it/s]\n",
      "Epoch 56/100: 100%|██████████| 236/236 [00:02<00:00, 92.45it/s]\n",
      "Epoch 57/100: 100%|██████████| 236/236 [00:02<00:00, 88.96it/s]\n",
      "Epoch 58/100: 100%|██████████| 236/236 [00:02<00:00, 94.12it/s]\n",
      "Epoch 59/100: 100%|██████████| 236/236 [00:02<00:00, 96.79it/s]\n",
      "Epoch 60/100: 100%|██████████| 236/236 [00:02<00:00, 97.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.0996\n",
      "Train Accuracy: 0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 236/236 [00:02<00:00, 94.55it/s]\n",
      "Epoch 62/100: 100%|██████████| 236/236 [00:02<00:00, 96.47it/s]\n",
      "Epoch 63/100: 100%|██████████| 236/236 [00:02<00:00, 96.32it/s]\n",
      "Epoch 64/100: 100%|██████████| 236/236 [00:02<00:00, 96.42it/s]\n",
      "Epoch 65/100: 100%|██████████| 236/236 [00:02<00:00, 89.43it/s]\n",
      "Epoch 66/100: 100%|██████████| 236/236 [00:02<00:00, 92.18it/s]\n",
      "Epoch 67/100: 100%|██████████| 236/236 [00:02<00:00, 81.89it/s]\n",
      "Epoch 68/100: 100%|██████████| 236/236 [00:02<00:00, 81.31it/s]\n",
      "Epoch 69/100: 100%|██████████| 236/236 [00:02<00:00, 91.33it/s]\n",
      "Epoch 70/100: 100%|██████████| 236/236 [00:02<00:00, 93.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0881\n",
      "Train Accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 236/236 [00:02<00:00, 92.98it/s]\n",
      "Epoch 72/100: 100%|██████████| 236/236 [00:02<00:00, 93.37it/s]\n",
      "Epoch 73/100: 100%|██████████| 236/236 [00:02<00:00, 92.48it/s]\n",
      "Epoch 74/100: 100%|██████████| 236/236 [00:02<00:00, 94.53it/s]\n",
      "Epoch 75/100: 100%|██████████| 236/236 [00:02<00:00, 91.39it/s]\n",
      "Epoch 76/100: 100%|██████████| 236/236 [00:02<00:00, 94.78it/s]\n",
      "Epoch 77/100: 100%|██████████| 236/236 [00:02<00:00, 93.90it/s]\n",
      "Epoch 78/100: 100%|██████████| 236/236 [00:02<00:00, 89.10it/s]\n",
      "Epoch 79/100: 100%|██████████| 236/236 [00:02<00:00, 92.51it/s]\n",
      "Epoch 80/100: 100%|██████████| 236/236 [00:02<00:00, 79.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0797\n",
      "Train Accuracy: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 236/236 [00:04<00:00, 58.59it/s]\n",
      "Epoch 82/100: 100%|██████████| 236/236 [00:03<00:00, 60.28it/s]\n",
      "Epoch 83/100: 100%|██████████| 236/236 [00:04<00:00, 53.98it/s]\n",
      "Epoch 84/100: 100%|██████████| 236/236 [00:04<00:00, 58.85it/s]\n",
      "Epoch 85/100: 100%|██████████| 236/236 [00:02<00:00, 92.62it/s]\n",
      "Epoch 86/100: 100%|██████████| 236/236 [00:02<00:00, 93.85it/s]\n",
      "Epoch 87/100: 100%|██████████| 236/236 [00:02<00:00, 89.97it/s]\n",
      "Epoch 88/100: 100%|██████████| 236/236 [00:02<00:00, 91.66it/s]\n",
      "Epoch 89/100: 100%|██████████| 236/236 [00:02<00:00, 90.79it/s]\n",
      "Epoch 90/100: 100%|██████████| 236/236 [00:02<00:00, 86.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0666\n",
      "Train Accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 236/236 [00:02<00:00, 81.74it/s]\n",
      "Epoch 92/100: 100%|██████████| 236/236 [00:02<00:00, 93.78it/s]\n",
      "Epoch 93/100: 100%|██████████| 236/236 [00:02<00:00, 94.59it/s]\n",
      "Epoch 94/100: 100%|██████████| 236/236 [00:02<00:00, 97.73it/s]\n",
      "Epoch 95/100: 100%|██████████| 236/236 [00:02<00:00, 93.46it/s]\n",
      "Epoch 96/100: 100%|██████████| 236/236 [00:02<00:00, 91.54it/s]\n",
      "Epoch 97/100: 100%|██████████| 236/236 [00:02<00:00, 95.09it/s]\n",
      "Epoch 98/100: 100%|██████████| 236/236 [00:02<00:00, 94.50it/s]\n",
      "Epoch 99/100: 100%|██████████| 236/236 [00:02<00:00, 95.33it/s]\n",
      "Epoch 100/100: 100%|██████████| 236/236 [00:02<00:00, 84.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0622\n",
      "Train Accuracy: 0.9916\n",
      "Model trained and saved at model_fold_4.pth\n",
      "Fold 5 - Accuracy: 0.8035, Kappa: 0.6063\n",
      "\n",
      "Cross-validation results:\n",
      "Mean Accuracy: 0.8050 (±0.0050)\n",
      "Mean Kappa: 0.6098 (±0.0102)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 295/295 [00:03<00:00, 90.08it/s] \n",
      "Epoch 2/100: 100%|██████████| 295/295 [00:02<00:00, 99.90it/s] \n",
      "Epoch 3/100: 100%|██████████| 295/295 [00:02<00:00, 99.49it/s] \n",
      "Epoch 4/100: 100%|██████████| 295/295 [00:04<00:00, 65.41it/s]\n",
      "Epoch 5/100: 100%|██████████| 295/295 [00:04<00:00, 60.90it/s]\n",
      "Epoch 6/100: 100%|██████████| 295/295 [00:05<00:00, 58.38it/s]\n",
      "Epoch 7/100: 100%|██████████| 295/295 [00:04<00:00, 70.35it/s]\n",
      "Epoch 8/100: 100%|██████████| 295/295 [00:04<00:00, 71.91it/s] \n",
      "Epoch 9/100: 100%|██████████| 295/295 [00:02<00:00, 100.70it/s]\n",
      "Epoch 10/100: 100%|██████████| 295/295 [00:02<00:00, 100.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3585\n",
      "Train Accuracy: 0.8827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 295/295 [00:03<00:00, 95.47it/s] \n",
      "Epoch 12/100: 100%|██████████| 295/295 [00:02<00:00, 100.11it/s]\n",
      "Epoch 13/100: 100%|██████████| 295/295 [00:02<00:00, 98.66it/s] \n",
      "Epoch 14/100: 100%|██████████| 295/295 [00:03<00:00, 92.29it/s] \n",
      "Epoch 15/100: 100%|██████████| 295/295 [00:02<00:00, 99.39it/s] \n",
      "Epoch 16/100: 100%|██████████| 295/295 [00:02<00:00, 99.85it/s] \n",
      "Epoch 17/100: 100%|██████████| 295/295 [00:02<00:00, 98.49it/s] \n",
      "Epoch 18/100: 100%|██████████| 295/295 [00:03<00:00, 98.15it/s] \n",
      "Epoch 19/100: 100%|██████████| 295/295 [00:03<00:00, 97.86it/s] \n",
      "Epoch 20/100: 100%|██████████| 295/295 [00:02<00:00, 99.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.2562\n",
      "Train Accuracy: 0.9367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 295/295 [00:02<00:00, 101.47it/s]\n",
      "Epoch 22/100: 100%|██████████| 295/295 [00:02<00:00, 98.72it/s] \n",
      "Epoch 23/100: 100%|██████████| 295/295 [00:02<00:00, 99.10it/s] \n",
      "Epoch 24/100: 100%|██████████| 295/295 [00:02<00:00, 99.91it/s] \n",
      "Epoch 25/100: 100%|██████████| 295/295 [00:02<00:00, 101.57it/s]\n",
      "Epoch 26/100: 100%|██████████| 295/295 [00:02<00:00, 102.58it/s]\n",
      "Epoch 27/100: 100%|██████████| 295/295 [00:03<00:00, 98.19it/s] \n",
      "Epoch 28/100: 100%|██████████| 295/295 [00:02<00:00, 100.86it/s]\n",
      "Epoch 29/100: 100%|██████████| 295/295 [00:03<00:00, 94.96it/s] \n",
      "Epoch 30/100: 100%|██████████| 295/295 [00:02<00:00, 100.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.1912\n",
      "Train Accuracy: 0.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 295/295 [00:02<00:00, 101.90it/s]\n",
      "Epoch 32/100: 100%|██████████| 295/295 [00:02<00:00, 102.54it/s]\n",
      "Epoch 33/100: 100%|██████████| 295/295 [00:03<00:00, 95.47it/s]\n",
      "Epoch 34/100: 100%|██████████| 295/295 [00:03<00:00, 75.73it/s]\n",
      "Epoch 35/100: 100%|██████████| 295/295 [00:03<00:00, 89.30it/s] \n",
      "Epoch 36/100: 100%|██████████| 295/295 [00:02<00:00, 104.27it/s]\n",
      "Epoch 37/100: 100%|██████████| 295/295 [00:03<00:00, 88.56it/s] \n",
      "Epoch 38/100: 100%|██████████| 295/295 [00:03<00:00, 87.83it/s] \n",
      "Epoch 39/100: 100%|██████████| 295/295 [00:03<00:00, 92.34it/s] \n",
      "Epoch 40/100: 100%|██████████| 295/295 [00:03<00:00, 88.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.1497\n",
      "Train Accuracy: 0.9698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 295/295 [00:03<00:00, 92.02it/s] \n",
      "Epoch 42/100: 100%|██████████| 295/295 [00:04<00:00, 72.93it/s]\n",
      "Epoch 43/100: 100%|██████████| 295/295 [00:03<00:00, 88.98it/s]\n",
      "Epoch 44/100: 100%|██████████| 295/295 [00:03<00:00, 87.19it/s]\n",
      "Epoch 45/100: 100%|██████████| 295/295 [00:03<00:00, 86.63it/s] \n",
      "Epoch 46/100: 100%|██████████| 295/295 [00:03<00:00, 88.18it/s] \n",
      "Epoch 47/100: 100%|██████████| 295/295 [00:03<00:00, 97.90it/s] \n",
      "Epoch 48/100: 100%|██████████| 295/295 [00:04<00:00, 70.90it/s]\n",
      "Epoch 49/100: 100%|██████████| 295/295 [00:03<00:00, 93.99it/s] \n",
      "Epoch 50/100: 100%|██████████| 295/295 [00:02<00:00, 107.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.1298\n",
      "Train Accuracy: 0.9751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 295/295 [00:02<00:00, 103.48it/s]\n",
      "Epoch 52/100: 100%|██████████| 295/295 [00:03<00:00, 78.11it/s] \n",
      "Epoch 53/100: 100%|██████████| 295/295 [00:03<00:00, 76.14it/s]\n",
      "Epoch 54/100: 100%|██████████| 295/295 [00:03<00:00, 87.19it/s]\n",
      "Epoch 55/100: 100%|██████████| 295/295 [00:03<00:00, 96.41it/s] \n",
      "Epoch 56/100: 100%|██████████| 295/295 [00:03<00:00, 85.52it/s]\n",
      "Epoch 57/100: 100%|██████████| 295/295 [00:02<00:00, 99.69it/s] \n",
      "Epoch 58/100: 100%|██████████| 295/295 [00:02<00:00, 100.34it/s]\n",
      "Epoch 59/100: 100%|██████████| 295/295 [00:02<00:00, 102.14it/s]\n",
      "Epoch 60/100: 100%|██████████| 295/295 [00:02<00:00, 102.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.1106\n",
      "Train Accuracy: 0.9802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 295/295 [00:03<00:00, 97.89it/s] \n",
      "Epoch 62/100: 100%|██████████| 295/295 [00:03<00:00, 88.86it/s]\n",
      "Epoch 63/100: 100%|██████████| 295/295 [00:03<00:00, 97.02it/s] \n",
      "Epoch 64/100: 100%|██████████| 295/295 [00:03<00:00, 95.80it/s]\n",
      "Epoch 65/100: 100%|██████████| 295/295 [00:03<00:00, 87.42it/s]\n",
      "Epoch 66/100: 100%|██████████| 295/295 [00:03<00:00, 91.13it/s]\n",
      "Epoch 67/100: 100%|██████████| 295/295 [00:03<00:00, 90.82it/s]\n",
      "Epoch 68/100: 100%|██████████| 295/295 [00:02<00:00, 99.76it/s] \n",
      "Epoch 69/100: 100%|██████████| 295/295 [00:02<00:00, 99.63it/s] \n",
      "Epoch 70/100: 100%|██████████| 295/295 [00:02<00:00, 101.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.0957\n",
      "Train Accuracy: 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 295/295 [00:02<00:00, 98.43it/s] \n",
      "Epoch 72/100: 100%|██████████| 295/295 [00:03<00:00, 95.48it/s] \n",
      "Epoch 73/100: 100%|██████████| 295/295 [00:03<00:00, 78.82it/s]\n",
      "Epoch 74/100: 100%|██████████| 295/295 [00:03<00:00, 88.15it/s]\n",
      "Epoch 75/100: 100%|██████████| 295/295 [00:03<00:00, 93.79it/s]\n",
      "Epoch 76/100: 100%|██████████| 295/295 [00:02<00:00, 98.53it/s] \n",
      "Epoch 77/100: 100%|██████████| 295/295 [00:02<00:00, 102.09it/s]\n",
      "Epoch 78/100: 100%|██████████| 295/295 [00:02<00:00, 102.40it/s]\n",
      "Epoch 79/100: 100%|██████████| 295/295 [00:02<00:00, 100.70it/s]\n",
      "Epoch 80/100: 100%|██████████| 295/295 [00:02<00:00, 100.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.0867\n",
      "Train Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 295/295 [00:03<00:00, 97.32it/s] \n",
      "Epoch 82/100: 100%|██████████| 295/295 [00:02<00:00, 99.84it/s] \n",
      "Epoch 83/100: 100%|██████████| 295/295 [00:03<00:00, 92.66it/s]\n",
      "Epoch 84/100: 100%|██████████| 295/295 [00:03<00:00, 78.24it/s]\n",
      "Epoch 85/100: 100%|██████████| 295/295 [00:03<00:00, 82.37it/s]\n",
      "Epoch 86/100: 100%|██████████| 295/295 [00:04<00:00, 72.82it/s]\n",
      "Epoch 87/100: 100%|██████████| 295/295 [00:03<00:00, 90.23it/s]\n",
      "Epoch 88/100: 100%|██████████| 295/295 [00:03<00:00, 75.50it/s] \n",
      "Epoch 89/100: 100%|██████████| 295/295 [00:03<00:00, 89.54it/s] \n",
      "Epoch 90/100: 100%|██████████| 295/295 [00:03<00:00, 96.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.0789\n",
      "Train Accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 295/295 [00:03<00:00, 95.69it/s] \n",
      "Epoch 92/100: 100%|██████████| 295/295 [00:03<00:00, 87.82it/s]\n",
      "Epoch 93/100: 100%|██████████| 295/295 [00:03<00:00, 92.82it/s]\n",
      "Epoch 94/100: 100%|██████████| 295/295 [00:03<00:00, 87.82it/s]\n",
      "Epoch 95/100: 100%|██████████| 295/295 [00:03<00:00, 88.47it/s]\n",
      "Epoch 96/100: 100%|██████████| 295/295 [00:03<00:00, 96.53it/s] \n",
      "Epoch 97/100: 100%|██████████| 295/295 [00:03<00:00, 95.20it/s]\n",
      "Epoch 98/100: 100%|██████████| 295/295 [00:02<00:00, 98.73it/s] \n",
      "Epoch 99/100: 100%|██████████| 295/295 [00:02<00:00, 99.31it/s] \n",
      "Epoch 100/100: 100%|██████████| 295/295 [00:03<00:00, 92.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.0734\n",
      "Train Accuracy: 0.9895\n",
      "Model trained and saved at final_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Ajout des imports nécessaires\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour entraîner et évaluer le modèle avec cross-validation\n",
    "def cross_validate_dnn(X, y, config, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    kappas = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        # Séparation des données\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Initialisation du modèle\n",
    "        model = DescriptorMLP(\n",
    "            config[\"input_size\"],\n",
    "            config[\"hidden_nodes\"],\n",
    "            config[\"hidden_layers\"],\n",
    "            config[\"dropout_rate\"]\n",
    "        )\n",
    "        \n",
    "        # Entraînement\n",
    "        train_params = {\n",
    "            \"batch_size\": config[\"batch_size\"],\n",
    "            \"learning_rate\": config[\"learning_rate\"],\n",
    "            \"epochs\": config[\"epochs\"],\n",
    "            \"save_path\": f\"model_fold_{fold}.pth\"\n",
    "        }\n",
    "        model = train_dnn_with_dataloader(X_train, y_train, model, **train_params)\n",
    "        \n",
    "        # Évaluation\n",
    "        y_pred = predict_mlp(model, X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        kappa = cohen_kappa_score(y_val, y_pred)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        kappas.append(kappa)\n",
    "        \n",
    "        print(f\"Fold {fold + 1} - Accuracy: {acc:.4f}, Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    print(\"\\nCross-validation results:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies):.4f} (±{np.std(accuracies):.4f})\")\n",
    "    print(f\"Mean Kappa: {np.mean(kappas):.4f} (±{np.std(kappas):.4f})\")\n",
    "    \n",
    "    return accuracies, kappas\n",
    "\n",
    "# Configuration du modèle\n",
    "config = {\n",
    "    \"input_size\": X_80.shape[1],\n",
    "    \"hidden_nodes\": 892,\n",
    "    \"hidden_layers\": 4,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "# Chargement de toutes les données\n",
    "X_all = np.vstack([X_80, X_20])\n",
    "y_all = np.concatenate([y_80, y_20])\n",
    "\n",
    "# Exécution de la cross-validation\n",
    "accuracies, kappas = cross_validate_dnn(X_all, y_all, config, n_splits=5)\n",
    "\n",
    "# Entraînement final sur toutes les données si nécessaire\n",
    "final_model = DescriptorMLP(\n",
    "    config[\"input_size\"],\n",
    "    config[\"hidden_nodes\"],\n",
    "    config[\"hidden_layers\"],\n",
    "    config[\"dropout_rate\"]\n",
    ")\n",
    "final_model = train_dnn_with_dataloader(X_all, y_all, final_model, \n",
    "                                      batch_size=config[\"batch_size\"],\n",
    "                                      learning_rate=config[\"learning_rate\"],\n",
    "                                      epochs=config[\"epochs\"],\n",
    "                                      save_path=\"final_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89df80c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 236/236 [00:03<00:00, 68.46it/s]\n",
      "Epoch 2/100: 100%|██████████| 236/236 [00:02<00:00, 86.86it/s]\n",
      "Epoch 3/100: 100%|██████████| 236/236 [00:02<00:00, 80.66it/s]\n",
      "Epoch 4/100: 100%|██████████| 236/236 [00:03<00:00, 67.08it/s]\n",
      "Epoch 5/100: 100%|██████████| 236/236 [00:02<00:00, 84.68it/s]\n",
      "Epoch 6/100: 100%|██████████| 236/236 [00:03<00:00, 74.31it/s]\n",
      "Epoch 7/100: 100%|██████████| 236/236 [00:02<00:00, 82.29it/s]\n",
      "Epoch 8/100: 100%|██████████| 236/236 [00:03<00:00, 78.41it/s]\n",
      "Epoch 9/100:  66%|██████▌   | 156/236 [00:02<00:01, 69.11it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     34\u001b[39m model = DescriptorMLP(\n\u001b[32m     35\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33minput_size\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     36\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mhidden_nodes\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     37\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mhidden_layers\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     38\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mdropout_rate\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     39\u001b[39m )\n\u001b[32m     40\u001b[39m train_params = {key: config[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msave_path\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m model = \u001b[43mtrain_dnn_with_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Predict on test set\u001b[39;00m\n\u001b[32m     43\u001b[39m y_pred = predict_mlp(model, X_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mtrain_dnn_with_dataloader\u001b[39m\u001b[34m(X_train, y_train, model, batch_size, learning_rate, epochs, save_path)\u001b[39m\n\u001b[32m     24\u001b[39m     optimizer.zero_grad()\n\u001b[32m     25\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     running_loss += loss.item()\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (epoch + \u001b[32m1\u001b[39m) % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/adam.py:456\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    454\u001b[39m         exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m.addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[32m    459\u001b[39m     step = step_t\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "train80 = pd.read_csv(\"train_data_80.csv\")\n",
    "train2O = pd.read_csv(\"train_data_20.csv\")\n",
    "X_80, smiles_list_80 = extract_selected_features(train80)\n",
    "X_20, smiles_list_20 = extract_selected_features(train2O)\n",
    "\n",
    "# Scale the data\n",
    "X_80 = StandardScaler().fit_transform(X_80)\n",
    "X_20 = StandardScaler().fit_transform(X_20)\n",
    "\n",
    "y_80 = train80['class']\n",
    "y_20 = train2O['class']\n",
    "\n",
    "# Split data\n",
    "X_train = X_80\n",
    "y_train = y_80\n",
    "X_test = X_20\n",
    "y_test = y_20\n",
    "\n",
    "# Model configuration\n",
    "config = {\n",
    "    \"input_size\": X_train.shape[1],\n",
    "    \"hidden_nodes\": 892,\n",
    "    \"hidden_layers\": 4,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_path\": \"descriptor_based_dnn.pth\"\n",
    "}\n",
    "\n",
    "# Initialize and train model\n",
    "model = DescriptorMLP(\n",
    "    config[\"input_size\"],\n",
    "    config[\"hidden_nodes\"],\n",
    "    config[\"hidden_layers\"],\n",
    "    config[\"dropout_rate\"]\n",
    ")\n",
    "train_params = {key: config[key] for key in [\"batch_size\", \"learning_rate\", \"epochs\", \"save_path\"]}\n",
    "model = train_dnn_with_dataloader(X_train, y_train, model, **train_params)\n",
    "# Predict on test set\n",
    "y_pred = predict_mlp(model, X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_score(y_test, y_pred):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09f4e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des probabilités prédites pour chaque molécule du test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_proba = model(X_test_tensor).squeeze().numpy()\n",
    "\n",
    "# Création du DataFrame avec smiles et proba\n",
    "df_pred = pd.DataFrame({\n",
    "    \"smiles\": smiles_list_20.values,\n",
    "    \"proba\": y_proba\n",
    "})\n",
    "\n",
    "# Sauvegarde au format CSV\n",
    "df_pred.to_csv(\"mlp_desc_proba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7473d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Charger le fichier test\n",
    "test_df = pd.read_csv(\"/Users/rayanedakhlaoui/Desktop/VivaAfricAI/Final/test/test_1.csv\")\n",
    "# Extraire les features du test\n",
    "X_test_submit, smiles_test_submit = extract_selected_features(test_df)\n",
    "\n",
    "# Appliquer le même scaler que pour le train (ici, on refait un fit_transform, mais idéalement il faudrait utiliser le scaler du train)\n",
    "X_test_submit = StandardScaler().fit_transform(X_test_submit)\n",
    "\n",
    "# Model configuration\n",
    "config = {\n",
    "    \"input_size\": X_train.shape[1],\n",
    "    \"hidden_nodes\": 892,\n",
    "    \"hidden_layers\": 4,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_path\": \"descriptor_based_dnn.pth\"\n",
    "}\n",
    "\n",
    "\n",
    "# Charger le modèle entraîné\n",
    "submission_model = DescriptorMLP(\n",
    "    config[\"input_size\"],\n",
    "    config[\"hidden_nodes\"],\n",
    "    config[\"hidden_layers\"],\n",
    "    config[\"dropout_rate\"]\n",
    ")\n",
    "submission_model.load_state_dict(torch.load(config[\"save_path\"]))\n",
    "submission_model.eval()\n",
    "\n",
    "# Prédire les probabilités\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test_submit, dtype=torch.float32)\n",
    "    y_pred_submit = submission_model(X_test_tensor).squeeze().numpy()\n",
    "\n",
    "# Générer le fichier de soumission\n",
    "submission_df = pd.DataFrame({\n",
    "    \"smiles\": smiles_test_submit.values,\n",
    "    \"proba\": y_pred_submit\n",
    "})\n",
    "submission_df.to_csv(\"prediction_mlp.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
